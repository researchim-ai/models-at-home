"""
Motels at Home Training Studio ‚Äî –í–∏–∑—É–∞–ª—å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –º–æ–¥–µ–ª–µ–π
======================================================================

–ó–∞–ø—É—Å–∫:
    streamlit run homellm/app/main.py
    
–∏–ª–∏:
    ./scripts/run_studio.sh
"""

import streamlit as st
import logging
import subprocess
import json
import time

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

import os
import signal
from pathlib import Path
from datetime import datetime
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import pandas as pd
import torch
from datasets import load_dataset, get_dataset_config_names, get_dataset_split_names, load_dataset_builder  # –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç
try:
    from .docs import render_docs
except ImportError:
    from docs import render_docs

# –ü—É—Ç–∏
PROJECT_ROOT = Path(__file__).parent.parent.parent
CONFIGS_DIR = PROJECT_ROOT / "configs"
DATASET_DIR = PROJECT_ROOT / "datasets"  # datasets —Å "s"!
OUTPUT_DIR = PROJECT_ROOT / "out"
RUNS_DIR = PROJECT_ROOT / ".runs"
RUNS_DIR.mkdir(exist_ok=True)

# ============================================================================
# Page Config
# ============================================================================

st.set_page_config(
    page_title="HomeLLM Training Studio",
    page_icon="üè†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS ‚Äî —á–∏—Å—Ç–∞—è —Ç—ë–º–Ω–∞—è —Ç–µ–º–∞ —Å —Ö–æ—Ä–æ—à–∏–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç–æ–º
st.markdown("""
<style>
    /* –ó–∞–≥–æ–ª–æ–≤–æ–∫ */
    .main-header {
        color: #ff6b6b;
        font-size: 2.5rem;
        font-weight: 800;
        text-align: center;
        margin-bottom: 0.5rem;
    }
    
    .sub-header {
        color: #888888;
        text-align: center;
        font-size: 1.1rem;
        margin-bottom: 2rem;
    }
    
    /* –°—Ç–∞—Ç—É—Å */
    .status-running {
        color: #22c55e !important;
        font-weight: bold;
    }
    
    .status-completed {
        color: #3b82f6 !important;
        font-weight: bold;
    }
    
    .status-error {
        color: #ef4444 !important;
        font-weight: bold;
    }
    
    /* ASCII art –±–ª–æ–∫ */
    .model-ascii {
        background: #1e1e1e;
        border: 1px solid #333;
        border-radius: 8px;
        padding: 1rem;
        font-family: 'Courier New', monospace;
        color: #00ff88;
        white-space: pre;
        overflow-x: auto;
    }
    
    /* –ö–∞—Ä—Ç–æ—á–∫–∏ –º–µ—Ç—Ä–∏–∫ */
    div[data-testid="metric-container"] {
        background: rgba(255, 255, 255, 0.05);
        border: 1px solid rgba(255, 255, 255, 0.1);
        border-radius: 8px;
        padding: 0.5rem;
    }
    
    /* –ö–Ω–æ–ø–∫–∏ –∑–∞–ø—É—Å–∫–∞ */
    .stButton > button[kind="primary"] {
        background: linear-gradient(90deg, #e94560, #ff6b6b);
        color: white !important;
        border: none;
        font-weight: 600;
    }
    
    /* Code –±–ª–æ–∫–∏ */
    pre {
        background: #0d1117 !important;
        color: #c9d1d9 !important;
        border: 1px solid #30363d !important;
    }
    
    code {
        color: #79c0ff !important;
    }
</style>
""", unsafe_allow_html=True)


# ============================================================================
# Persistence ‚Äî —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞–º–∏
# ============================================================================

ACTIVE_RUN_FILE = RUNS_DIR / "active_run.json"


def save_active_run(run_id: str, config: dict = None):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–π run –≤ —Ñ–∞–π–ª."""
    data = {
        "run_id": run_id,
        "started_at": datetime.now().isoformat(),
        "config": config or {}
    }
    with open(ACTIVE_RUN_FILE, "w") as f:
        json.dump(data, f, indent=2)


def load_active_run() -> dict | None:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–π run –∏–∑ —Ñ–∞–π–ª–∞."""
    if not ACTIVE_RUN_FILE.exists():
        return None
    try:
        with open(ACTIVE_RUN_FILE) as f:
            return json.load(f)
    except:
        return None


def clear_active_run():
    """–û—á–∏—Å—Ç–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–π run."""
    if ACTIVE_RUN_FILE.exists():
        ACTIVE_RUN_FILE.unlink()


def restore_session_state():
    """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–µ—Å—Å–∏–∏ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏."""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π –∞–∫—Ç–∏–≤–Ω—ã–π run
    active = load_active_run()
    if active and active.get("run_id"):
        run_id = active["run_id"]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ run –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
        run_dir = RUNS_DIR / run_id
        if run_dir.exists():
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∂–∏–≤ –ª–∏ –ø—Ä–æ—Ü–µ—Å—Å
            pid_path = run_dir / "pid"
            process_alive = False
            if pid_path.exists():
                try:
                    with open(pid_path) as f:
                        pid = int(f.read().strip())
                    os.kill(pid, 0)  # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞
                    process_alive = True
                except PermissionError:
                    process_alive = True
                except (ProcessLookupError, ValueError, PermissionError):
                    pass
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            st.session_state.current_run_id = run_id
            st.session_state.training_active = process_alive
            
            # –ï—Å–ª–∏ –ø—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à—ë–Ω, –æ—á–∏—â–∞–µ–º active_run
            if not process_alive:
                metrics_path = run_dir / "metrics.json"
                if metrics_path.exists():
                    try:
                        with open(metrics_path) as f:
                            metrics = json.load(f)
                        if metrics.get("status") in ["completed", "error", "stopped"]:
                            clear_active_run()
                    except:
                        pass


# ============================================================================
# Session State
# ============================================================================

if "training_process" not in st.session_state:
    st.session_state.training_process = None
if "current_run_id" not in st.session_state:
    st.session_state.current_run_id = None
if "training_active" not in st.session_state:
    st.session_state.training_active = False
if "selected_chat_model" not in st.session_state:
    st.session_state.selected_chat_model = None

# –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–∏ –ø–µ—Ä–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–µ
if "session_restored" not in st.session_state:
    restore_session_state()
    st.session_state.session_restored = True


# ============================================================================
# Helper Functions
# ============================================================================

def get_available_datasets():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤."""
    datasets = []
    if DATASET_DIR.exists():
        for f in DATASET_DIR.glob("*.jsonl"):
            size_mb = f.stat().st_size / (1024 * 1024)
            datasets.append((f.name, f"{size_mb:.1f} MB"))
        for f in DATASET_DIR.glob("*.txt"):
            size_mb = f.stat().st_size / (1024 * 1024)
            datasets.append((f.name, f"{size_mb:.1f} MB"))
    return datasets


def get_gpu_info():
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö GPU."""
    gpus = []
    if torch.cuda.is_available():
        for i in range(torch.cuda.device_count()):
            props = torch.cuda.get_device_properties(i)
            memory_gb = props.total_memory / (1024**3)
            gpus.append({
                "id": i,
                "name": props.name,
                "memory_gb": round(memory_gb, 1),
                "compute_capability": f"{props.major}.{props.minor}",
            })
    return gpus


def get_available_configs():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö accelerate –∫–æ–Ω—Ñ–∏–≥–æ–≤."""
    configs = []
    if CONFIGS_DIR.exists():
        for f in CONFIGS_DIR.glob("*.yaml"):
            name = f.stem.replace("accelerate_", "").replace("_", " ").title()
            configs.append({
                "file": f.name,
                "name": name,
                "path": str(f),
            })
    return configs


# –û–ø–∏—Å–∞–Ω–∏—è —Ç–∏–ø–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞
PARALLEL_TYPES = {
    "default": {
        "name": "Single GPU / CPU",
        "type": "None",
        "description": "–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ –±–µ–∑ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞",
        "icon": "üñ•Ô∏è",
    },
    "multi_gpu": {
        "name": "Multi-GPU (DDP)",
        "type": "Data Parallel",
        "description": "Distributed Data Parallel ‚Äî –∫–∞–∂–¥–∞—è GPU –ø–æ–ª—É—á–∞–µ—Ç –∫–æ–ø–∏—é –º–æ–¥–µ–ª–∏ –∏ —á–∞—Å—Ç—å –±–∞—Ç—á–∞",
        "icon": "üîÑ",
    },
    "fsdp": {
        "name": "FSDP",
        "type": "Data Parallel + Model Parallel",
        "description": "Fully Sharded Data Parallel ‚Äî –º–æ–¥–µ–ª—å —à–∞—Ä–¥–∏—Ä—É–µ—Ç—Å—è –º–µ–∂–¥—É GPU (PyTorch native)",
        "icon": "‚ö°",
    },
    "deepspeed_zero2": {
        "name": "DeepSpeed ZeRO-2",
        "type": "Data Parallel + Optimizer Parallel",
        "description": "–®–∞—Ä–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –º–µ–∂–¥—É GPU",
        "icon": "üöÄ",
    },
    "deepspeed_zero3": {
        "name": "DeepSpeed ZeRO-3",
        "type": "Full Model Parallel",
        "description": "–ü–æ–ª–Ω–æ–µ —à–∞—Ä–¥–∏—Ä–æ–≤–∞–Ω–∏–µ: –º–æ–¥–µ–ª—å + –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä + –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã",
        "icon": "üí™",
    },
    "deepspeed_zero3_offload": {
        "name": "ZeRO-3 + CPU Offload",
        "type": "Model Parallel + CPU Offload",
        "description": "–ü–æ–ª–Ω–æ–µ —à–∞—Ä–¥–∏—Ä–æ–≤–∞–Ω–∏–µ + –≤—ã–≥—Ä—É–∑–∫–∞ –Ω–∞ CPU –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ VRAM",
        "icon": "üßä",
    },
}


def estimate_parameters(hidden_size: int, num_layers: int, vocab_size: int = 50257) -> int:
    """–ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤."""
    # Embedding: vocab_size * hidden_size
    embed = vocab_size * hidden_size
    # Each layer: attention (4 * hidden^2) + FFN (8 * hidden^2) + norms
    per_layer = 4 * hidden_size ** 2 + 8 * hidden_size ** 2 + 2 * hidden_size
    # LM head is tied, so not counted
    total = embed + num_layers * per_layer
    return total


def format_params(n: int) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤."""
    if n >= 1e9:
        return f"{n/1e9:.2f}B"
    elif n >= 1e6:
        return f"{n/1e6:.1f}M"
    elif n >= 1e3:
        return f"{n/1e3:.1f}K"
    return str(n)


def format_time(seconds: float) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏."""
    if seconds < 60:
        return f"{seconds:.0f}s"
    elif seconds < 3600:
        return f"{seconds/60:.1f}m"
    else:
        return f"{seconds/3600:.1f}h"


def load_metrics(run_id: str) -> dict:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ —Ñ–∞–π–ª–∞."""
    metrics_path = RUNS_DIR / run_id / "metrics.json"
    if metrics_path.exists():
        try:
            with open(metrics_path) as f:
                return json.load(f)
        except:
            pass
    return None


def start_training(config: dict) -> str:
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É –≤ —Ñ–æ–Ω–µ."""
    run_id = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # –õ–û–ì–ò–ö–ê –ü–£–¢–ï–ô
    # config["output_dir"] - —ç—Ç–æ –∫–æ—Ä–µ–Ω—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä out/my_model)
    # –ú—ã —Ö–æ—Ç–∏–º —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç—ã –≤ out/my_model/run_2023.../checkpoint_...
    experiment_root = Path(PROJECT_ROOT) / config.get("output_dir", "out/default")
    run_output_dir = experiment_root / run_id
    
    # –û–±–Ω–æ–≤–ª—è–µ–º output_dir –≤ –∫–æ–Ω—Ñ–∏–≥–µ, —á—Ç–æ–±—ã worker —Å–æ—Ö—Ä–∞–Ω—è–ª —Ç—É–¥–∞
    config["output_dir"] = str(run_output_dir)
    
    # –ü–∞–ø–∫–∞ –¥–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∑–∞–ø—É—Å–∫–∞ (–ª–æ–≥–∏, –º–µ—Ç—Ä–∏–∫–∏)
    # –ú–æ–∂–Ω–æ —Ö—Ä–∞–Ω–∏—Ç—å –∏—Ö —Ç–∞–º –∂–µ, –≥–¥–µ –∏ —á–µ–∫–ø–æ–∏–Ω—Ç—ã, –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
    run_dir = RUNS_DIR / run_id # –û—Å—Ç–∞–≤–ª—è–µ–º .runs –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –ª–æ–≥–æ–≤ —Å—Ç—Ä–∏–º–ª–∏—Ç–∞
    run_dir.mkdir(parents=True, exist_ok=True)
    run_output_dir.mkdir(parents=True, exist_ok=True) # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –≤–µ—Å–æ–≤
    
    config_path = run_dir / "config.json"
    metrics_path = run_dir / "metrics.json"
    stdout_path = run_dir / "stdout.log"
    stderr_path = run_dir / "stderr.log"
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥
    with open(config_path, "w") as f:
        json.dump(config, f, indent=2)
    
    # –°–æ–∑–¥–∞—ë–º –Ω–∞—á–∞–ª—å–Ω—ã–π metrics —Ñ–∞–π–ª
    with open(metrics_path, "w") as f:
        json.dump({"status": "starting", "current_step": 0}, f)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–º–∞–Ω–¥—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞ distributed
    distributed_mode = config.get("distributed_mode", "default")
    config_file = config.get("config_file")
    num_gpus = config.get("num_gpus", 1)
    
    if distributed_mode != "default" and config_file:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º accelerate launch —Å –∫–æ–Ω—Ñ–∏–≥–æ–º
        cmd = [
            "accelerate", "launch",
            "--config_file", config_file,
            "--num_processes", str(num_gpus),
            "--gradient_accumulation_steps", str(config.get("gradient_accumulation", 1)),
            "-m", "homellm.app.trainer_worker",
            "--config", str(config_path),
            "--metrics", str(metrics_path)
        ]
    else:
        # –û–±—ã—á–Ω—ã–π –∑–∞–ø—É—Å–∫
        cmd = [
            "python", "-m", "homellm.app.trainer_worker",
            "--config", str(config_path),
            "--metrics", str(metrics_path)
        ]
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–º–∞–Ω–¥—É –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    cmd_path = run_dir / "command.txt"
    with open(cmd_path, "w") as f:
        f.write(" ".join(cmd))
    
    stdout_file = open(stdout_path, "w")
    stderr_file = open(stderr_path, "w")
    
    process = subprocess.Popen(
        cmd,
        cwd=str(PROJECT_ROOT),
        stdout=stdout_file,
        stderr=stderr_file,
        start_new_session=True,  # –û—Ç–¥–µ–ª—è–µ–º –æ—Ç —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞
    )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º PID –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    pid_path = run_dir / "pid"
    with open(pid_path, "w") as f:
        f.write(str(process.pid))
    
    return run_id, process


def stop_training():
    """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É."""
    stopped = False
    
    # –ü—Ä–æ–±—É–µ–º –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–æ PID –∏–∑ —Ñ–∞–π–ª–∞ (–±–æ–ª–µ–µ –Ω–∞–¥—ë–∂–Ω–æ)
    if st.session_state.current_run_id:
        pid_path = RUNS_DIR / st.session_state.current_run_id / "pid"
        if pid_path.exists():
            try:
                with open(pid_path) as f:
                    pid = int(f.read().strip())
                # –°–Ω–∞—á–∞–ª–∞ SIGTERM, –ø–æ—Ç–æ–º SIGKILL –µ—Å–ª–∏ –Ω–µ –ø–æ–º–æ–≥–ª–æ
                os.kill(pid, signal.SIGTERM)
                stopped = True
                
                # –ñ–¥—ë–º –Ω–µ–º–Ω–æ–≥–æ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º
                time.sleep(0.5)
                try:
                    os.kill(pid, 0)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∂–∏–≤ –ª–∏ –ø—Ä–æ—Ü–µ—Å—Å
                    os.kill(pid, signal.SIGKILL)  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É–±–∏–≤–∞–µ–º
                except ProcessLookupError:
                    pass  # –ü—Ä–æ—Ü–µ—Å—Å —É–∂–µ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è
            except Exception as e:
                pass
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        metrics_path = RUNS_DIR / st.session_state.current_run_id / "metrics.json"
        if metrics_path.exists():
            try:
                with open(metrics_path) as f:
                    metrics = json.load(f)
                metrics["status"] = "stopped"
                with open(metrics_path, "w") as f:
                    json.dump(metrics, f, indent=2)
            except:
                pass
    
    # –¢–∞–∫–∂–µ –ø—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ subprocess
    if st.session_state.training_process:
        try:
            st.session_state.training_process.terminate()
            st.session_state.training_process.wait(timeout=2)
        except:
            try:
                st.session_state.training_process.kill()
            except:
                pass
        st.session_state.training_process = None
    
    st.session_state.training_active = False
    
    # –û—á–∏—â–∞–µ–º active_run
    clear_active_run()
    
    return stopped


def is_process_running(run_id: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –∑–∞–ø—É—â–µ–Ω –ª–∏ –ø—Ä–æ—Ü–µ—Å—Å."""
    pid_path = RUNS_DIR / run_id / "pid"
    if not pid_path.exists():
        return False
    
    try:
        with open(pid_path) as f:
            pid = int(f.read().strip())
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –ø—Ä–æ—Ü–µ—Å—Å
        os.kill(pid, 0)
        return True
    except PermissionError:
        # –ü—Ä–æ—Ü–µ—Å—Å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –Ω–æ —É –Ω–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∑–∞–ø—É—â–µ–Ω –æ—Ç –¥—Ä—É–≥–æ–≥–æ —é–∑–µ—Ä–∞)
        # –°—á–∏—Ç–∞–µ–º, —á—Ç–æ –æ–Ω –∂–∏–≤
        return True
    except (ProcessLookupError, ValueError, FileNotFoundError):
        return False


# ============================================================================
# UI Components
# ============================================================================

def render_header():
    st.markdown("# üè† Models at Home Training Studio")
    st.caption("–í–∏–∑—É–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–æ–º–∞")


def get_nested_value(data: dict, path: str):
    """–ü–æ–ª—É—á–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –ø—É—Ç–∏.
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
    - 'key1.key2' - –≤–ª–æ–∂–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞—Ä–∏
    - 'messages [—Å–ø–∏—Å–æ–∫ –∏–∑ N —ç–ª.]' - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–µ—Å—å —Å–ø–∏—Å–æ–∫
    - 'messages[].content' - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ–ª—è –∏–∑ –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
    - 'messages[0]' - –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç —Å–ø–∏—Å–∫–∞
    """
    if not path: return None
    
    # –£–±–∏—Ä–∞–µ–º —Å—É—Ñ—Ñ–∏–∫—Å—ã —Ç–∏–ø–∞ " [—Å–ø–∏—Å–æ–∫]" –∏–ª–∏ " [—Å–ø–∏—Å–æ–∫ –∏–∑ 3 —ç–ª.]"
    import re
    path = re.sub(r' \[—Å–ø–∏—Å–æ–∫.*?\]$', '', path)
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—É—Ç–µ–π —Ç–∏–ø–∞ 'messages[].content' (–≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å–ø–∏—Å–∫–∞)
    if "[]." in path:
        parts = path.split("[].", 1)
        list_path = parts[0]
        remaining_path = parts[1]
        
        list_val = get_nested_value(data, list_path)
        if isinstance(list_val, list):
            results = []
            for item in list_val:
                if isinstance(item, dict):
                    val = get_nested_value(item, remaining_path)
                    results.append(val)
            return results
        return None
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—É—Ç–µ–π —Ç–∏–ø–∞ 'messages[0]' (–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∏–Ω–¥–µ–∫—Å)
    if "[" in path and "]" in path:
        # –ü–∞—Ä—Å–∏–º –∏–Ω–¥–µ–∫—Å
        match = re.search(r'\[(\d+)\]', path)
        if match:
            idx = int(match.group(1))
            base_path = path[:match.start()]
            after_path = path[match.end():]
            if after_path.startswith('.'):
                after_path = after_path[1:]
            
            base_val = get_nested_value(data, base_path)
            if isinstance(base_val, list) and 0 <= idx < len(base_val):
                if after_path:
                    return get_nested_value(base_val[idx], after_path)
                return base_val[idx]
            return None
    
    # –û–±—ã—á–Ω—ã–π –ø—É—Ç—å —á–µ—Ä–µ–∑ —Ç–æ—á–∫–∏
    keys = path.split('.')
    curr = data
    try:
        for k in keys:
            if isinstance(curr, dict):
                curr = curr.get(k)
            elif isinstance(curr, list) and k.isdigit():
                curr = curr[int(k)]
            else:
                return None
            if curr is None: return None
        return curr
    except:
        return None


def get_dataset_columns(file_path: str):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ (–≤–∫–ª—é—á–∞—è –≤–ª–æ–∂–µ–Ω–Ω—ã–µ) –∏ –ø—Ä–∏–º–µ—Ä."""
    path = Path(file_path)
    if not path.exists():
        return [], {}
        
    try:
        sample_data = {}
        if path.suffix == ".jsonl":
            with open(path, "r", encoding="utf-8") as f:
                line = f.readline()
                if line:
                    sample_data = json.loads(line)
        elif path.suffix == ".json":
            with open(path, "r", encoding="utf-8") as f:
                data = json.load(f)
                if isinstance(data, list) and len(data) > 0:
                    sample_data = data[0]
                elif isinstance(data, dict):
                    # –ï—Å–ª–∏ —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å –∫–æ–ª–æ–Ω–æ–∫, –ø—Ä–æ—Å—Ç–æ –±–µ—Ä–µ–º –∫–ª—é—á–∏
                    return list(data.keys()), {k: v[0] if isinstance(v, list) else v for k, v in data.items()}
        elif path.suffix == ".csv":
            import csv
            with open(path, "r", encoding="utf-8") as f:
                reader = csv.DictReader(f)
                row = next(reader, None)
                if row:
                    sample_data = row
        
        if sample_data:
            # –î–ª—è get_dataset_columns –Ω–∞–º –Ω–µ –Ω—É–∂–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø–ª–æ—Å–∫–∏–µ –∫–ª—é—á–∏, 
            # —Ç–∞–∫ –∫–∞–∫ render_sft_main_config —Ç–µ–ø–µ—Ä—å —Å–∞–º —Å—Ç—Ä–æ–∏—Ç –¥–µ—Ä–µ–≤–æ.
            # –ù–æ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –æ—Å—Ç–∞–≤–∏–º –≤–æ–∑–≤—Ä–∞—Ç sample_data
            return [], sample_data
            
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        return [], {}
    
    return [], {}


def flatten_json_structure(d: dict, parent_path: str = '', depth: int = 0) -> list:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç JSON –≤ –ø–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –¥–µ—Ä–µ–≤–∞."""
    items = []
    for k, v in d.items():
        current_path = f"{parent_path}.{k}" if parent_path else k
        
        if isinstance(v, dict):
            # –ü–∞–ø–∫–∞
            items.append({"type": "folder", "key": k, "path": current_path, "depth": depth, "val": ""})
            items.extend(flatten_json_structure(v, current_path, depth + 1))
        elif isinstance(v, list):
            # –°–ø–∏—Å–æ–∫
            items.append({"type": "list", "key": k, "path": current_path, "depth": depth, "val": f"List[{len(v)}]"})
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–µ—Ä–≤–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
            if v:
                if isinstance(v[0], dict):
                    items.extend(flatten_json_structure(v[0], current_path, depth + 1))
                else:
                    # –°–ø–∏—Å–æ–∫ –ø—Ä–∏–º–∏—Ç–∏–≤–æ–≤ (—Å—Ç—Ä–æ–∫ –∏ —Ç.–¥.) - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫ –ª–∏—Å—Ç
                    # –ù–æ –Ω–∞–º –Ω–µ –Ω—É–∂–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç, –ø—Ä–æ—Å—Ç–æ –¥–∞–µ–º –ø–æ–Ω—è—Ç—å —á—Ç–æ –≤–Ω—É—Ç—Ä–∏
                    # –î–ª—è SFT –º—ã –æ–±—ã—á–Ω–æ –Ω–µ –≤—ã–±–∏—Ä–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Å–ø–∏—Å–∫–∞ –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏, –∞ –≤–µ—Å—å —Å–ø–∏—Å–æ–∫
                    pass
        else:
            # –õ–∏—Å—Ç (–∑–Ω–∞—á–µ–Ω–∏–µ)
            items.append({"type": "leaf", "key": k, "path": current_path, "depth": depth, "val": str(v)})
    return items


def get_all_leaf_paths(data, parent_path: str = '', depth: int = 0, max_depth: int = 10) -> list:
    """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø–æ–ª—É—á–∞–µ—Ç –í–°–ï –ø—É—Ç–∏ –∫ –∑–Ω–∞—á–µ–Ω–∏—è–º, –≤–∫–ª—é—á–∞—è –≥–ª—É–±–æ–∫—É—é –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å."""
    if depth > max_depth:
        return []
    
    paths = []
    
    if isinstance(data, dict):
        for k, v in data.items():
            current_path = f"{parent_path}.{k}" if parent_path else k
            
            if isinstance(v, dict):
                # –í–ª–æ–∂–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å - —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ
                paths.extend(get_all_leaf_paths(v, current_path, depth + 1, max_depth))
            elif isinstance(v, list):
                # –î–æ–±–∞–≤–ª—è–µ–º —Å–∞–º —Å–ø–∏—Å–æ–∫ –∫–∞–∫ –æ–ø—Ü–∏—é (–¥–ª—è chat-—Ñ–æ—Ä–º–∞—Ç–∞)
                paths.append(f"{current_path} [—Å–ø–∏—Å–æ–∫ –∏–∑ {len(v)} —ç–ª.]")
                # –†–∞—Å–∫—Ä—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–µ—Ä–≤–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
                if v:
                    if isinstance(v[0], dict):
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ª—è –≤–Ω—É—Ç—Ä–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å–ø–∏—Å–∫–∞
                        for inner_k, inner_v in v[0].items():
                            inner_path = f"{current_path}[].{inner_k}"
                            if isinstance(inner_v, dict):
                                paths.extend(get_all_leaf_paths(inner_v, inner_path, depth + 2, max_depth))
                            elif isinstance(inner_v, list):
                                paths.append(f"{inner_path} [—Å–ø–∏—Å–æ–∫]")
                                if inner_v and isinstance(inner_v[0], dict):
                                    paths.extend(get_all_leaf_paths(inner_v[0], f"{inner_path}[]", depth + 3, max_depth))
                            else:
                                paths.append(inner_path)
                    else:
                        # –°–ø–∏—Å–æ–∫ –ø—Ä–∏–º–∏—Ç–∏–≤–æ–≤
                        paths.append(f"{current_path}[0]")
            else:
                # –ü—Ä–æ—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                paths.append(current_path)
    
    return paths


def render_sft_main_config(data_path: str):
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ç–æ—Ä SFT ‚Äî –∞–≤—Ç–æ–¥–µ—Ç–µ–∫—Ç + —Ä—É—á–Ω–æ–π –≤—ã–±–æ—Ä."""
    st.markdown("### üõ†Ô∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è SFT")
    
    columns, sample = get_dataset_columns(data_path)
    
    if not sample:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –∏–ª–∏ –æ–Ω –ø—É—Å—Ç.")
        return {}
    
    # ===== –ê–í–¢–û–î–ï–¢–ï–ö–¢ –§–û–†–ú–ê–¢–ê =====
    def detect_chat_field(data: dict) -> tuple:
        """–ò—â–µ—Ç –ø–æ–ª–µ —Å–æ —Å–ø–∏—Å–∫–æ–º —Å–æ–æ–±—â–µ–Ω–∏–π (chat-—Ñ–æ—Ä–º–∞—Ç)."""
        for key, value in data.items():
            if isinstance(value, list) and value and isinstance(value[0], dict):
                first_item = value[0]
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –ø–æ–ª—è –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ role/content
                has_role = any(k.lower() in ['role', 'from', 'type'] for k in first_item.keys())
                has_content = any(k.lower() in ['content', 'value', 'text', 'message'] for k in first_item.keys())
                if has_role and has_content:
                    return key, value
        return None, None
    
    chat_field, chat_value = detect_chat_field(sample)
    detected_format = "chat" if chat_field else "instruct"
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –ø—É—Ç–∏ –¥–ª—è instruct —Ä–µ–∂–∏–º–∞
    all_paths = get_all_leaf_paths(sample)
    simple_fields = [k for k in sample.keys() if not isinstance(sample[k], (dict, list))]
    
    col_json, col_config = st.columns([1, 1])
    
    # ===== –õ–ï–í–ê–Ø –ö–û–õ–û–ù–ö–ê: JSON –ø—Ä–µ–≤—å—é =====
    with col_json:
        st.markdown("#### üìÑ –ü—Ä–∏–º–µ—Ä –∑–∞–ø–∏—Å–∏:")
        with st.container(height=500):
            st.json(sample, expanded=True)
    
    # ===== –ü–†–ê–í–ê–Ø –ö–û–õ–û–ù–ö–ê: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è =====
    with col_config:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –∞–≤—Ç–æ–¥–µ—Ç–µ–∫—Ç –Ω–∞—à–µ–ª
        if detected_format == "chat":
            st.success(f"üîç **–ê–≤—Ç–æ–¥–µ—Ç–µ–∫—Ç:** –Ω–∞–π–¥–µ–Ω Chat-—Ñ–æ—Ä–º–∞—Ç –≤ –ø–æ–ª–µ `{chat_field}`")
        else:
            st.info("üîç **–ê–≤—Ç–æ–¥–µ—Ç–µ–∫—Ç:** Instruct-—Ñ–æ—Ä–º–∞—Ç (–æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–æ–ª—è)")
        
        # –ü–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å —Ä–µ–∂–∏–º–∞
        format_choice = st.radio(
            "–§–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö:",
            ["üí¨ Chat (—Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π)", "üìù Instruct (–æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–æ–ª—è)"],
            index=0 if detected_format == "chat" else 1,
            key="sft_format_choice",
            horizontal=True
        )
        
        is_chat = "Chat" in format_choice
        
        st.markdown("---")
        
        sft_columns = {}
        
        if is_chat:
            # ===== CHAT –†–ï–ñ–ò–ú =====
            st.markdown("#### üí¨ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Chat-—Ñ–æ—Ä–º–∞—Ç–∞")
            
            # –í—ã–±–æ—Ä –ø–æ–ª—è —Å–æ —Å–ø–∏—Å–∫–æ–º —Å–æ–æ–±—â–µ–Ω–∏–π
            list_fields = [k for k, v in sample.items() if isinstance(v, list) and v and isinstance(v[0], dict)]
            
            if not list_fields:
                st.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ–π —Å–æ —Å–ø–∏—Å–∫–æ–º —Å–æ–æ–±—â–µ–Ω–∏–π!")
                return {}
            
            messages_field = st.selectbox(
                "üìã –ü–æ–ª–µ —Å —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏:",
                list_fields,
                index=list_fields.index(chat_field) if chat_field in list_fields else 0,
                key="sft_messages_field"
            )
            
            messages = sample[messages_field]
            first_msg = messages[0]
            inner_fields = list(first_msg.keys())
            
            st.caption(f"–ù–∞–π–¥–µ–Ω–æ {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π")
            
            # –ú–∞–ø–ø–∏–Ω–≥ –ø–æ–ª–µ–π
            c1, c2 = st.columns(2)
            
            role_guess = next((f for f in inner_fields if f.lower() in ['role', 'from', 'type']), inner_fields[0])
            content_guess = next((f for f in inner_fields if f.lower() in ['content', 'value', 'text', 'message']), inner_fields[-1])
            
            role_field = c1.selectbox(
                "–ü–æ–ª–µ **—Ä–æ–ª–∏**:",
                inner_fields,
                index=inner_fields.index(role_guess) if role_guess in inner_fields else 0,
                key="sft_chat_role"
            )
            content_field = c2.selectbox(
                "–ü–æ–ª–µ **—Ç–µ–∫—Å—Ç–∞**:",
                inner_fields,
                index=inner_fields.index(content_guess) if content_guess in inner_fields else 0,
                key="sft_chat_content"
            )
            
            # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ä–æ–ª–∏
            unique_roles = sorted(set(str(m.get(role_field, "")) for m in messages))
            st.caption(f"–†–æ–ª–∏ –≤ –¥–∞–Ω–Ω—ã—Ö: `{', '.join(unique_roles)}`")
            
            # –ú–∞–ø–ø–∏–Ω–≥ —Ä–æ–ª–µ–π
            st.markdown("**–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ä–æ–ª–µ–π:**")
            c1, c2, c3 = st.columns(3)
            
            sys_guess = next((r for r in unique_roles if 'system' in r.lower()), None)
            user_guess = next((r for r in unique_roles if r.lower() in ['user', 'human']), unique_roles[0] if unique_roles else "")
            asst_guess = next((r for r in unique_roles if r.lower() in ['assistant', 'gpt', 'bot']), unique_roles[-1] if len(unique_roles) > 1 else "")
            
            role_system = c1.selectbox("‚öôÔ∏è System =", ["(–Ω–µ—Ç)"] + unique_roles,
                index=(unique_roles.index(sys_guess) + 1) if sys_guess in unique_roles else 0, key="sft_map_sys")
            role_user = c2.selectbox("üë§ User =", unique_roles,
                index=unique_roles.index(user_guess) if user_guess in unique_roles else 0, key="sft_map_user")
            role_assistant = c3.selectbox("ü§ñ Assistant =", unique_roles,
                index=unique_roles.index(asst_guess) if asst_guess in unique_roles else 0, key="sft_map_asst")
            
            sft_columns = {
                "format": "chat",
                "messages_path": messages_field,
                "role_field": role_field,
                "content_field": content_field,
                "role_system": role_system if role_system != "(–Ω–µ—Ç)" else "",
                "role_user": role_user,
                "role_assistant": role_assistant
            }
            
        else:
            # ===== INSTRUCT –†–ï–ñ–ò–ú =====
            st.markdown("#### üìù –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Instruct-—Ñ–æ—Ä–º–∞—Ç–∞")
            st.caption("–í—ã–±–µ—Ä–∏—Ç–µ –ø–æ–ª—è –¥–ª—è –∫–∞–∂–¥–æ–π —Ä–æ–ª–∏:")
            
            # –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—É—Ç–∏
            field_options = ["(–Ω–µ –≤—ã–±—Ä–∞–Ω–æ)"] + all_paths
            
            system_path = st.selectbox("‚öôÔ∏è **System** (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):", field_options, index=0, key="sft_inst_sys")
            user_path = st.selectbox("üë§ **User** (–≤–æ–ø—Ä–æ—Å/–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è):", field_options, index=0, key="sft_inst_user")
            assistant_path = st.selectbox("ü§ñ **Assistant** (–æ—Ç–≤–µ—Ç):", field_options, index=0, key="sft_inst_asst")
            
            if user_path == "(–Ω–µ –≤—ã–±—Ä–∞–Ω–æ)" or assistant_path == "(–Ω–µ –≤—ã–±—Ä–∞–Ω–æ)":
                st.warning("üëÜ –í—ã–±–µ—Ä–∏—Ç–µ –ø–æ–ª—è **User** –∏ **Assistant**")
                return {}
            
            sft_columns = {
                "format": "instruct",
                "instruction": user_path,
                "output": assistant_path,
                "system_field": system_path if system_path != "(–Ω–µ –≤—ã–±—Ä–∞–Ω–æ)" else ""
            }
        
        # ===== –ù–ê–°–¢–†–û–ô–ö–ò –®–ê–ë–õ–û–ù–ê =====
        st.markdown("---")
        with st.expander("üè∑Ô∏è –¢–µ–≥–∏ –∏ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç", expanded=False):
            default_system = st.text_input("System prompt (–ø–æ —É–º–æ–ª—á.):", "You are a helpful assistant.", key="sft_def_sys")
            tc1, tc2 = st.columns(2)
            user_tag = tc1.text_input("User tag:", "### User:", key="sft_tag_user")
            assistant_tag = tc2.text_input("Assistant tag:", "### Assistant:", key="sft_tag_asst")
        
        if 'default_system' not in dir():
            default_system, user_tag, assistant_tag = "You are a helpful assistant.", "### User:", "### Assistant:"
        
        sft_template = {
            "system": default_system,
            "separator": "\n\n",
            "user_tag": user_tag,
            "bot_tag": assistant_tag
        }
        
        # ===== –ü–†–ï–í–¨–Æ =====
        st.markdown("---")
        st.markdown("#### üëÅÔ∏è –ü—Ä–µ–≤—å—é:")
        
        try:
            sep = "\n\n"
            preview = ""
            
            if sft_columns["format"] == "chat":
                messages = sample[sft_columns["messages_path"]]
                sys_text = default_system
                
                for msg in messages:
                    role = str(msg.get(sft_columns["role_field"], ""))
                    content = str(msg.get(sft_columns["content_field"], ""))
                    
                    if role == sft_columns["role_system"]:
                        sys_text = content
                    elif role == sft_columns["role_user"]:
                        preview += f"{user_tag}\n{content[:200]}{'...' if len(content) > 200 else ''}{sep}"
                    elif role == sft_columns["role_assistant"]:
                        preview += f"{assistant_tag}\n{content[:200]}{'...' if len(content) > 200 else ''}{sep}"
                
                preview = f"{sys_text}{sep}" + preview + "<|endoftext|>"
            else:
                user_val = str(get_nested_value(sample, sft_columns["instruction"]) or "")[:300]
                asst_val = str(get_nested_value(sample, sft_columns["output"]) or "")[:300]
                sys_val = default_system
                if sft_columns.get("system_field"):
                    field_sys = get_nested_value(sample, sft_columns["system_field"])
                    if field_sys: sys_val = str(field_sys)[:200]
                
                preview = f"{sys_val}{sep}{user_tag}\n{user_val}{sep}{assistant_tag}\n{asst_val}<|endoftext|>"
            
            with st.container(height=400):
                st.code(preview, language=None)
            
            st.success("‚úÖ –ì–æ—Ç–æ–≤–æ!")
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞: {e}")

    return {"sft_columns": sft_columns, "sft_template": sft_template}


def render_model_config():
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ç–æ—Ä –º–æ–¥–µ–ª–∏ –≤ —Å–∞–π–¥–±–∞—Ä–µ."""
    st.sidebar.header("üß† –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ –†–µ–∂–∏–º")
    
    # –†–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è
    stage_options = {
        "pretrain": "Pretraining (—Å –Ω—É–ª—è)",
        "sft": "SFT (Fine-Tuning)"
    }
    selected_stage = st.sidebar.selectbox(
        "–≠—Ç–∞–ø –æ–±—É—á–µ–Ω–∏—è",
        options=list(stage_options.keys()),
        format_func=lambda x: stage_options[x],
        help="–í—ã–±–µ—Ä–∏—Ç–µ —ç—Ç–∞–ø: –æ–±—É—á–µ–Ω–∏–µ —Å –Ω—É–ª—è –∏–ª–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏"
    )
    
    # –ò–º—è –º–æ–¥–µ–ª–∏ (–¥–ª—è –ø–∞–ø–∫–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞)
    model_name_default = "home_pretrain" if selected_stage == "pretrain" else "home_sft"
    model_name = st.sidebar.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞", value=model_name_default, help="–ò–º—è –ø–∞–ø–∫–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
    
    base_model_path = None
    
    if selected_stage == "sft":
        st.sidebar.subheader("üì¶ –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å")
        available = get_available_models()
        if not available:
            st.sidebar.warning("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è SFT. –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ Pretrain –º–æ–¥–µ–ª—å!")
            # –ú–æ–∂–Ω–æ –¥–∞—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –≤–≤–µ—Å—Ç–∏ –ø—É—Ç—å –≤—Ä—É—á–Ω—É—é
            base_model_path = st.sidebar.text_input("–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –≤—Ä—É—á–Ω—É—é", placeholder="/path/to/model")
        else:
            # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ–ø—Ü–∏–π
            model_options = [m["name"] for m in available]
            selected_base_name = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å", options=model_options)
            # –ù–∞—Ö–æ–¥–∏–º –ø—É—Ç—å
            base_model_path = next(m["path"] for m in available if m["name"] == selected_base_name)
            
            st.sidebar.caption(f"–ü—É—Ç—å: `{base_model_path}`")
    
    # –§–ª–∞–≥, —á—Ç–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
    loaded_config = None
    
    if selected_stage == "sft" and base_model_path:
        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥
        try:
            base_path = Path(base_model_path)
            # –í–∞—Ä–∏–∞–Ω—Ç 1: config.json –ø—Ä—è–º–æ –≤ –ø–∞–ø–∫–µ (final_model)
            cfg_path = base_path / "config.json"
            # –í–∞—Ä–∏–∞–Ω—Ç 2: —ç—Ç–æ —á–µ–∫–ø–æ–∏–Ω—Ç
            if not cfg_path.exists():
                # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ run_config.json –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π
                if (base_path.parent / "run_config.json").exists():
                    cfg_path = base_path.parent / "run_config.json"
                elif (base_path / "run_config.json").exists(): # –∏–Ω–æ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–∞–∫
                     cfg_path = base_path / "run_config.json"
            
            if cfg_path.exists():
                with open(cfg_path) as f:
                    loaded_config = json.load(f)
                st.sidebar.success("‚úÖ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏")
            else:
                st.sidebar.warning("‚ö†Ô∏è config.json –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—Ä—É—á–Ω—É—é")
        except Exception as e:
             st.sidebar.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è config.json: {e}")

    st.sidebar.subheader("‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏")
    
    if loaded_config:
        # –†–µ–∂–∏–º —Ç–æ–ª—å–∫–æ —á—Ç–µ–Ω–∏—è –¥–ª—è SFT —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º –∫–æ–Ω—Ñ–∏–≥–æ–º
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–Ω—ã—Ö –∏–º–µ–Ω –∫–ª—é—á–µ–π)
        hidden_size = loaded_config.get("hidden_size", 512)
        # num_hidden_layers - HF, num_layers - –Ω–∞—à –∫–æ–Ω—Ñ–∏–≥
        num_layers = loaded_config.get("num_hidden_layers", loaded_config.get("num_layers", 8))
        num_attention_heads = loaded_config.get("num_attention_heads", loaded_config.get("n_heads", 8))
        max_position_embeddings = loaded_config.get("max_position_embeddings", loaded_config.get("seq_len", 512))
        
        # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–º–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∫–∞–∫ –æ–∂–∏–¥–∞–µ—Ç—Å—è
        n_heads = num_attention_heads
        seq_len = max_position_embeddings
        
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç–æ–º/–º–µ—Ç—Ä–∏–∫–∞–º–∏
        c1, c2 = st.sidebar.columns(2)
        c1.metric("Hidden Size", hidden_size)
        c2.metric("Layers", num_layers)
        c1.metric("Heads", n_heads)
        c2.metric("Seq Len", seq_len)
        
        st.sidebar.info("üîí –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω—ã (–Ω–∞—Å–ª–µ–¥—É—é—Ç—Å—è –æ—Ç –±–∞–∑—ã)")
        
    else:
        # –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        d_hid, d_layers = 512, 8
        
        if selected_stage == "sft":
            st.sidebar.caption("‚ö†Ô∏è –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç —Å –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é!")

        # –ü—Ä–µ—Å–µ—Ç—ã
        preset = st.sidebar.selectbox(
            "–ü—Ä–µ—Å–µ—Ç",
            ["Tiny (25M)", "Small (80M)", "Medium (200M)", "Large (400M)", "Custom"],
            index=0
        )
        
        presets = {
            "Tiny (25M)": (512, 8, 8),
            "Small (80M)": (768, 12, 12),
            "Medium (200M)": (1024, 16, 16),
            "Large (400M)": (1280, 20, 20),
        }
        
        if preset != "Custom" and preset in presets:
            default_h, default_l, default_n = presets[preset]
        else:
            default_h, default_l, default_n = 512, 8, 8
        
        hidden_size = st.sidebar.slider(
            "Hidden Size", 
            min_value=128, 
            max_value=2048, 
            value=default_h, 
            step=64,
            help="–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ—è"
        )
        
        num_layers = st.sidebar.slider(
            "Num Layers", 
            min_value=2, 
            max_value=32, 
            value=default_l,
            help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ—ë–≤ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞"
        )
        
        n_heads = st.sidebar.slider(
            "Attention Heads", 
            min_value=2, 
            max_value=32, 
            value=default_n,
            help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–æ–ª–æ–≤ –≤–Ω–∏–º–∞–Ω–∏—è"
        )
        
        seq_len = st.sidebar.selectbox(
            "Seq Length",
            [256, 512, 1024, 2048],
            index=1,
            help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"
        )
    
    # –û—Ü–µ–Ω–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    est_params = estimate_parameters(hidden_size, num_layers)
    st.sidebar.metric("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã (‚âà)", format_params(est_params))
    
    return {
        "stage": selected_stage,
        "base_model_path": base_model_path,
        "model_name_input": model_name,
        "hidden_size": hidden_size,
        "num_layers": num_layers,
        "n_heads": n_heads,
        "seq_len": seq_len,
    }


def render_training_config():
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ç–æ—Ä –æ–±—É—á–µ–Ω–∏—è –≤ —Å–∞–π–¥–±–∞—Ä–µ."""
    st.sidebar.header("‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è")
    
    batch_size = st.sidebar.slider(
        "Batch Size",
        min_value=1,
        max_value=256,
        value=4,
        help="–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞"
    )
    
    grad_accum = st.sidebar.slider(
        "Gradient Accumulation",
        min_value=1,
        max_value=32,
        value=8,
        help="–®–∞–≥–∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞"
    )
    
    st.sidebar.caption(f"Effective batch: {batch_size * grad_accum}")
    
    learning_rate = st.sidebar.select_slider(
        "Learning Rate",
        options=[1e-5, 3e-5, 5e-5, 1e-4, 3e-4, 5e-4, 1e-3],
        value=5e-4,
        format_func=lambda x: f"{x:.0e}"
    )
    
    warmup_steps = st.sidebar.number_input(
        "Warmup Steps",
        min_value=0,
        max_value=10000,
        value=1000
    )
    
    # –í—ã–±–æ—Ä: epochs –∏–ª–∏ max_steps
    training_mode = st.sidebar.radio(
        "–†–µ–∂–∏–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏",
        ["–ü–æ —ç–ø–æ—Ö–∞–º", "–ü–æ —à–∞–≥–∞–º"],
        help="–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞–∫ –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏"
    )
    
    if training_mode == "–ü–æ —ç–ø–æ—Ö–∞–º":
        epochs = st.sidebar.number_input(
            "Epochs",
            min_value=1,
            max_value=10,
            value=1
        )
        max_steps = None
    else:
        epochs = 1
        max_steps = st.sidebar.number_input(
            "Max Steps",
            min_value=100,
            max_value=1000000,
            value=10000,
            step=1000,
            help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –æ–±—É—á–µ–Ω–∏—è"
        )
    
    mixed_precision = st.sidebar.selectbox(
        "Mixed Precision",
        ["no", "fp16", "bf16"],
        index=2,
        help="bf16 —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è Ampere+ GPU"
    )
    
    grad_checkpoint = st.sidebar.checkbox(
        "Gradient Checkpointing",
        value=False,
        help="–≠–∫–æ–Ω–æ–º–∏—Ç VRAM, –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ"
    )
    
    return {
        "batch_size": batch_size,
        "gradient_accumulation": grad_accum,
        "learning_rate": learning_rate,
        "warmup_steps": warmup_steps,
        "epochs": epochs,
        "max_steps": max_steps,
        "mixed_precision": mixed_precision,
        "grad_checkpoint": grad_checkpoint,
    }


def render_dataset_config(stage="pretrain"):
    """–í—ã–±–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ (—Ç–æ–ª—å–∫–æ –≤—ã–±–æ—Ä —Ñ–∞–π–ª–∞)."""
    st.sidebar.header("üìÅ –î–∞—Ç–∞—Å–µ—Ç")
    
    datasets = get_available_datasets()
    
    if datasets:
        dataset_options = [f"{name} ({size})" for name, size in datasets]
        selected = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç", dataset_options)
        selected_name = selected.split(" (")[0]
        data_path = str(DATASET_DIR / selected_name)
    else:
        st.sidebar.warning("–î–∞—Ç–∞—Å–µ—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ datasets/")
        data_path = st.sidebar.text_input("–ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É", "datasets/data.jsonl")
    
    return {"data_path": data_path}


def render_output_config(model_name="training_run"):
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤—ã–≤–æ–¥–∞."""
    st.sidebar.header("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ")
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø—É—Ç—å: out/{model_name}
    default_dir = f"out/{model_name}"
    
    output_dir = st.sidebar.text_input(
        "Output Directory (Experiment Root)",
        value=default_dir,
        help="–ö–æ—Ä–Ω–µ–≤–∞—è –ø–∞–ø–∫–∞ –¥–ª—è –≤—Å–µ—Ö –∑–∞–ø—É—Å–∫–æ–≤ —ç—Ç–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞"
    )
    
    save_every = st.sidebar.number_input(
        "Save Checkpoint Every N Steps",
        min_value=100,
        max_value=50000,
        value=200,
        step=100,
        help="–ö–∞–∫ —á–∞—Å—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç—ã"
    )
    
    log_every = st.sidebar.number_input(
        "Log Every N Steps",
        min_value=1,
        max_value=1000,
        value=10,
        help="–ö–∞–∫ —á–∞—Å—Ç–æ –æ–±–Ω–æ–≤–ª—è—Ç—å –º–µ—Ç—Ä–∏–∫–∏"
    )
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞—Ö
    output_path = PROJECT_ROOT / output_dir
    if output_path.exists():
        checkpoints = list(output_path.glob("checkpoint_*"))
        final_model = output_path / "final_model"
        
        if checkpoints or final_model.exists():
            st.sidebar.caption(f"üì¶ –ù–∞–π–¥–µ–Ω–æ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤: {len(checkpoints)}")
            if final_model.exists():
                st.sidebar.caption("‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
    
    return {
        "output_dir": output_dir,
        "save_every": save_every,
        "log_every": log_every,
        "tokenizer_path": "gpt2"
    }


def get_available_models():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (—Ä–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫)."""
    models = []
    
    # –ò—â–µ–º —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ –≤ out/
    if OUTPUT_DIR.exists():
        # –ò—â–µ–º –ª—é–±—ã–µ config.json –≤–Ω—É—Ç—Ä–∏ out/
        for config_file in OUTPUT_DIR.rglob("config.json"):
            model_dir = config_file.parent
            
            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø–∞–ø–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –ø–æ—Ö–æ–∂–∏ –Ω–∞ –º–æ–¥–µ–ª–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ª–æ–≥–∏)
            # –ö—Ä–∏—Ç–µ—Ä–∏–π –º–æ–¥–µ–ª–∏: –Ω–∞–ª–∏—á–∏–µ config.json + (pytorch_model.bin –∏–ª–∏ model.safetensors –∏–ª–∏ adapter_model.bin)
            has_weights = (
                (model_dir / "pytorch_model.bin").exists() or 
                (model_dir / "model.safetensors").exists() or
                (model_dir / "adapter_model.bin").exists()
            )
            
            if has_weights:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø (final –∏–ª–∏ checkpoint)
                m_type = "checkpoint" if "checkpoint" in model_dir.name else "final"
                if model_dir.name == "final_model": m_type = "final"
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –∫—Ä–∞—Å–∏–≤–æ–µ –∏–º—è
                # –ë–µ—Ä–µ–º –ø—É—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ OUTPUT_DIR
                rel_path = model_dir.relative_to(OUTPUT_DIR)
                models.append({
                    "name": str(rel_path),
                    "path": str(model_dir),
                    "type": m_type,
                    "time": model_dir.stat().st_mtime
                })
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–Ω–æ–≤—ã–µ —Å–≤–µ—Ä—Ö—É)
    models.sort(key=lambda x: x["time"], reverse=True)
    return models


def render_distributed_config():
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è distributed training."""
    st.sidebar.header("üñ•Ô∏è GPU –∏ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU
    gpus = get_gpu_info()
    
    if gpus:
        st.sidebar.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ GPU: {len(gpus)}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ GPU
        for gpu in gpus:
            st.sidebar.markdown(f"""
            **GPU {gpu['id']}**: {gpu['name']}  
            üìä VRAM: {gpu['memory_gb']} GB | CC: {gpu['compute_capability']}
            """)
        
        # –í—ã–±–æ—Ä GPU –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        gpu_options = [f"GPU {g['id']}: {g['name']}" for g in gpus]
        if len(gpus) > 1:
            selected_gpus = st.sidebar.multiselect(
                "–í—ã–±–µ—Ä–∏—Ç–µ GPU",
                options=gpu_options,
                default=gpu_options,
                help="–í—ã–±–µ—Ä–∏—Ç–µ GPU –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"
            )
            num_gpus = len(selected_gpus)
            gpu_ids = [gpu_options.index(g) for g in selected_gpus]
        else:
            num_gpus = 1
            gpu_ids = [0]
            st.sidebar.info("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è GPU")
    else:
        st.sidebar.warning("‚ö†Ô∏è GPU –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω CPU")
        num_gpus = 0
        gpu_ids = []
    
    st.sidebar.markdown("---")
    
    # –í—ã–±–æ—Ä —Ç–∏–ø–∞ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞
    st.sidebar.subheader("‚ö° –¢–∏–ø –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –æ–ø—Ü–∏–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Ä–µ–∂–∏–º
    if num_gpus == 0:
        available_modes = ["default"]
        recommended_idx = 0
    elif num_gpus == 1:
        available_modes = ["default", "deepspeed_zero3_offload"]
        recommended_idx = 0
    else:
        # –ü—Ä–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö GPU —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º multi_gpu –∏–ª–∏ fsdp
        available_modes = ["multi_gpu", "fsdp", "deepspeed_zero2", "deepspeed_zero3", "deepspeed_zero3_offload", "default"]
        recommended_idx = 0  # multi_gpu –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ–ø—Ü–∏–∏ –¥–ª—è selectbox
    mode_options = []
    for i, mode in enumerate(available_modes):
        info = PARALLEL_TYPES[mode]
        label = f"{info['icon']} {info['name']}"
        if i == recommended_idx and num_gpus > 1:
            label += " ‚≠ê"  # –û—Ç–º–µ—á–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π
        mode_options.append(label)
    
    selected_mode_display = st.sidebar.selectbox(
        "–†–µ–∂–∏–º",
        options=mode_options,
        index=recommended_idx,
        help="–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"
    )
    
    # –ù–∞—Ö–æ–¥–∏–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º
    selected_idx = mode_options.index(selected_mode_display)
    selected_mode = available_modes[selected_idx]
    mode_info = PARALLEL_TYPES[selected_mode]
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ
    st.sidebar.markdown(f"""
    <div style="background: rgba(255,255,255,0.05); padding: 10px; border-radius: 8px; margin: 10px 0;">
    <b>–¢–∏–ø:</b> {mode_info['type']}<br>
    <small>{mode_info['description']}</small>
    </div>
    """, unsafe_allow_html=True)
    
    # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –µ—Å–ª–∏ –≤—ã–±—Ä–∞–Ω single GPU –ø—Ä–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö
    if num_gpus > 1 and selected_mode == "default":
        st.sidebar.warning(f"‚ö†Ô∏è –í—ã–±—Ä–∞–Ω Single GPU, –Ω–æ –¥–æ—Å—Ç—É–ø–Ω–æ {num_gpus} GPU. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º Multi-GPU!")
    
    # –ö–æ–Ω—Ñ–∏–≥ —Ñ–∞–π–ª
    config_file = None
    if selected_mode != "default":
        config_path = CONFIGS_DIR / f"accelerate_{selected_mode}.yaml"
        if config_path.exists():
            config_file = str(config_path)
            st.sidebar.caption(f"üìÑ –ö–æ–Ω—Ñ–∏–≥: `{config_path.name}`")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Ç–æ–≥–æ–≤—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∑–∞–ø—É—Å–∫–∞
    st.sidebar.markdown("---")
    st.sidebar.subheader("üöÄ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–ø—É—Å–∫–∞")
    
    if num_gpus == 0:
        launch_info = "**–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ:** CPU"
    elif selected_mode == "default":
        launch_info = f"**–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ:** GPU {gpu_ids[0] if gpu_ids else 0}"
    else:
        launch_info = f"**–£—Å—Ç—Ä–æ–π—Å—Ç–≤–∞:** {num_gpus} √ó GPU\n**–†–µ–∂–∏–º:** {mode_info['type']}"
    
    st.sidebar.info(launch_info)
    
    return {
        "distributed_mode": selected_mode,
        "num_gpus": num_gpus,
        "gpu_ids": gpu_ids,
        "config_file": config_file,
        "parallel_type": mode_info['type'],
    }


@st.fragment(run_every=3)  # –ê–≤—Ç–æ–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ 3 —Å–µ–∫—É–Ω–¥—ã
def live_metrics_fragment():
    """Fragment –¥–ª—è –∂–∏–≤–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –±–µ–∑ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã."""
    if not st.session_state.current_run_id:
        st.info("–í—ã–±–µ—Ä–∏—Ç–µ run –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –º–µ—Ç—Ä–∏–∫")
        return
    
    run_id = st.session_state.current_run_id
    metrics = load_metrics(run_id)
    process_alive = is_process_running(run_id)
    
    # –°—Ç–∞—Ç—É—Å
    if process_alive:
        st.success(f"üü¢ –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–ø—É—â–µ–Ω (Run: {run_id})")
    else:
        if metrics and metrics.get("status") == "completed":
            duration = metrics.get("training_duration", "unknown")
            st.success(f"‚úÖ –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {duration} (Run: {run_id})")
        elif metrics and metrics.get("status") == "error":
            st.error(f"‚ùå –û—à–∏–±–∫–∞ (Run: {run_id})")
        elif metrics and metrics.get("status") == "stopped":
            st.warning(f"‚èπÔ∏è –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ (Run: {run_id})")
        else:
            st.info(f"üìã –ü—Ä–æ—Å–º–æ—Ç—Ä –º–µ—Ç—Ä–∏–∫ (Run: {run_id})")
    
    if metrics:
        render_metrics_dashboard(metrics)
    else:
        st.info("–ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")


def render_metrics_dashboard(metrics: dict):
    """–î–∞—à–±–æ—Ä–¥ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è."""
    
    status = metrics.get("status", "unknown")
    
    # Status indicator
    status_emoji = {
        "training": "üü¢", 
        "completed": "‚úÖ", 
        "error": "‚ùå",
        "initializing": "‚è≥",
        "loading_tokenizer": "‚è≥",
        "loading_dataset": "‚è≥",
        "building_model": "‚è≥",
        "saving_model": "üíæ",
    }.get(status, "‚è≥")
    
    st.subheader(f"{status_emoji} –°—Ç–∞—Ç—É—Å: {status.upper()}")
    
    # Metrics cards
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        current_step = metrics.get("current_step", 0)
        total_steps = metrics.get("total_steps", 1)
        progress = current_step / total_steps * 100 if total_steps > 0 else 0
        st.metric("–ü—Ä–æ–≥—Ä–µ—Å—Å", f"{progress:.1f}%", f"Step {current_step}/{total_steps}")
    
    with col2:
        loss = metrics.get("current_loss", 0)
        st.metric("Loss", f"{loss:.4f}")
    
    with col3:
        lr = metrics.get("current_lr", 0)
        st.metric("Learning Rate", f"{lr:.2e}")
    
    with col4:
        eta = metrics.get("eta_seconds", 0)
        elapsed = metrics.get("elapsed_seconds", 0)
        st.metric("–í—Ä–µ–º—è", f"{format_time(elapsed)}", delta=f"–û—Å—Ç: {format_time(eta)}", delta_color="normal")
    
    # Progress bar
    st.progress(min(progress / 100, 1.0))
    
    # Charts
    if metrics.get("loss_history"):
        col1, col2 = st.columns(2)
        
        with col1:
            # Loss chart
            fig_loss = go.Figure()
            fig_loss.add_trace(go.Scatter(
                x=metrics["steps_history"],
                y=metrics["loss_history"],
                mode='lines',
                name='Loss',
                line=dict(color='#e94560', width=2)
            ))
            fig_loss.update_layout(
                title="Training Loss",
                xaxis_title="Step",
                yaxis_title="Loss",
                template="plotly_dark",
                height=300,
                margin=dict(l=0, r=0, t=40, b=0)
            )
            st.plotly_chart(fig_loss, key=f"loss_chart_{metrics.get('current_step')}")
        
        with col2:
            # LR chart
            fig_lr = go.Figure()
            fig_lr.add_trace(go.Scatter(
                x=metrics["steps_history"],
                y=metrics["lr_history"],
                mode='lines',
                name='LR',
                line=dict(color='#60a5fa', width=2)
            ))
            fig_lr.update_layout(
                title="Learning Rate Schedule",
                xaxis_title="Step",
                yaxis_title="LR",
                template="plotly_dark",
                height=300,
                margin=dict(l=0, r=0, t=40, b=0)
            )
            st.plotly_chart(fig_lr, key=f"lr_chart_{metrics.get('current_step')}")
    
    # Checkpoints
    if metrics.get("checkpoints"):
        with st.expander("üì¶ Checkpoints"):
            for ckpt in metrics["checkpoints"]:
                st.text(f"Step {ckpt['step']}: {ckpt['path']}")
    
    # GPU —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    gpu_stats = metrics.get("gpu_stats", [])
    if gpu_stats:
        st.subheader("üñ•Ô∏è –ù–∞–≥—Ä—É–∑–∫–∞ GPU")
        
        cols = st.columns(len(gpu_stats))
        for i, (col, gpu) in enumerate(zip(cols, gpu_stats)):
            with col:
                st.markdown(f"**GPU {gpu['id']}**")
                
                # Memory bar
                mem_percent = gpu.get('memory_percent', 0)
                st.progress(min(mem_percent / 100, 1.0), text=f"VRAM: {gpu['memory_used_gb']:.1f} / {gpu['memory_total_gb']:.1f} GB ({mem_percent:.0f}%)")
                
                # Utilization
                util = gpu.get('utilization')
                if util is not None:
                    st.progress(min(util / 100, 1.0), text=f"–ó–∞–≥—Ä—É–∑–∫–∞: {util}%")
                else:
                    st.caption("–ó–∞–≥—Ä—É–∑–∫–∞: N/A")
    
    # Error
    if metrics.get("error"):
        st.error("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏")
        with st.expander("–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –æ—à–∏–±–∫–∏ (Traceback)", expanded=True):
            st.code(metrics['error'], language="python")
    
    # –õ–æ–≥–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞
    if st.session_state.current_run_id:
        run_dir = RUNS_DIR / st.session_state.current_run_id
        stderr_path = run_dir / "stderr.log"
        stdout_path = run_dir / "stdout.log"
        
        with st.expander("üìã –õ–æ–≥–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞"):
            col1, col2 = st.columns(2)
            
            with col1:
                st.caption("stdout (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 500 —Å—Ç—Ä–æ–∫)")
                if stdout_path.exists():
                    with open(stdout_path) as f:
                        lines = f.readlines()
                        content = "".join(lines[-500:])
                        st.code(content if content else "(–ø—É—Å—Ç–æ)", language=None)
            
            with col2:
                st.caption("stderr (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 500 —Å—Ç—Ä–æ–∫)")
                if stderr_path.exists():
                    with open(stderr_path) as f:
                        lines = f.readlines()
                        content = "".join(lines[-500:])
                        st.code(content if content else "(–ø—É—Å—Ç–æ)", language=None)



def download_hf_dataset(repo_id, subset, split, limit_type, limit_val, limit_bytes, save_path, filters=None):
    """–§—É–Ω–∫—Ü–∏—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞."""
    try:
        status_text = f"–ù–∞—á–∏–Ω–∞–µ–º —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ: {repo_id}..."
        st.toast(status_text)
        print(status_text)
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã stream=True —á—Ç–æ–±—ã –Ω–µ –∫–∞—á–∞—Ç—å –≤—Å–µ –≤ –ø–∞–º—è—Ç—å
        ds = load_dataset(repo_id, subset, split=split, streaming=True)
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª
        save_path = DATASET_DIR / save_path
        save_path.parent.mkdir(exist_ok=True)
        
        count = 0
        current_bytes = 0
        
        with open(save_path, "w", encoding="utf-8") as f:
            for item in ds:
                # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤
                if filters:
                    # –§–∏–ª—å—Ç—Ä –ø–æ score
                    if "score_col" in filters and "min_score" in filters:
                         col = filters["score_col"]
                         min_s = filters["min_score"]
                         # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –∏ —Ç–∏–ø–∞
                         if col in item and item[col] is not None:
                             try:
                                 val = float(item[col])
                                 if val < min_s:
                                     continue
                             except ValueError:
                                 pass
                    
                    # –§–∏–ª—å—Ç—Ä –ø–æ —è–∑—ã–∫—É
                    if "lang_col" in filters and "target_lang" in filters:
                         col = filters["lang_col"]
                         target = filters["target_lang"]
                         if col in item and item[col] is not None:
                             val = str(item[col])
                             if target.lower() not in val.lower():
                                 continue
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ JSONL
                line = json.dumps(item, ensure_ascii=False) + "\n"
                line_bytes = len(line.encode('utf-8'))
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–æ–≤
                if limit_type == "–°—Ç—Ä–æ–∫–∏ (–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ)" and count >= limit_val:
                    break
                if limit_type == "–ì–ë (–†–∞–∑–º–µ—Ä)" and (current_bytes + line_bytes) > limit_bytes:
                    break
                    
                f.write(line)
                count += 1
                current_bytes += line_bytes
                
                if count % 1000 == 0:
                    print(f"Downloaded {count} lines, {current_bytes / 1024**2:.2f} MB")

        st.success(f"–ì–æ—Ç–æ–≤–æ! –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {count} —Å—Ç—Ä–æ–∫ ({current_bytes / 1024**2:.2f} MB) –≤ {save_path}")
        return True

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞: {e}")
        import traceback
        print(traceback.format_exc())
        return False


def render_data_manager():
    """–í–∫–ª–∞–¥–∫–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã–º–∏."""
    st.header("üíæ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã–º–∏")
    
    col_upload, col_list = st.columns([1, 2])
    
    with col_upload:
        # –°–µ–∫—Ü–∏—è 1: –ó–∞–≥—Ä—É–∑–∫–∞ –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        with st.expander("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤", expanded=False):
            uploaded_files = st.file_uploader(
                "–ü–µ—Ä–µ—Ç–∞—â–∏—Ç–µ —Ñ–∞–π–ª—ã —Å—é–¥–∞", 
                type=["jsonl", "txt", "json"], 
                accept_multiple_files=True
            )
            
            if uploaded_files:
                if st.button("üì• –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª—ã"):
                    for uploaded_file in uploaded_files:
                        save_path = DATASET_DIR / uploaded_file.name
                        with open(save_path, "wb") as f:
                            f.write(uploaded_file.getbuffer())
                        st.toast(f"–§–∞–π–ª {uploaded_file.name} —Å–æ—Ö—Ä–∞–Ω—ë–Ω!", icon="‚úÖ")
                    time.sleep(1)
                    st.rerun()

        # –°–µ–∫—Ü–∏—è 2: –ó–∞–≥—Ä—É–∑–∫–∞ —Å HuggingFace
        st.subheader("ü§ó –°–∫–∞—á–∞—Ç—å —Å HuggingFace")
        # –°–ª–æ–≤–∞—Ä—å –ø—Ä–µ—Å–µ—Ç–æ–≤: {–Ω–∞–∑–≤–∞–Ω–∏–µ: (repo_id, subset, split)}
        presets = {
            "üü¢ Pretrain: FineWeb-2 (Russian)": ("HuggingFaceFW/fineweb-2", "rus_Cyrl", "train"),
            "üü¢ Pretrain: FineWeb-Edu (Educational)": ("HuggingFaceFW/fineweb-edu", "default", "train"),
            "üü¢ Pretrain: Wikitext-103": ("wikitext", "wikitext-103-v1", "train"),
            "üîµ SFT: OpenOrca-ru": ("d0rj/OpenOrca-ru", "default", "train"),
            "üîµ SFT: ru-instruct": ("d0rj/ru-instruct", "default", "train"),
            "üîµ SFT: GrandMaster-PRO-MAX": ("Vikhrmodels/GrandMaster-PRO-MAX", "default", "train"),
            "üìù –í–≤–µ—Å—Ç–∏ –≤—Ä—É—á–Ω—É—é...": (None, None, None),
        }
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ñ–æ–ª—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (FineWeb-2 Russian)
        if "hf_repo_id_input" not in st.session_state:
            st.session_state.hf_repo_id_input = "HuggingFaceFW/fineweb-2"
        if "hf_subset_default" not in st.session_state:
            st.session_state.hf_subset_default = "rus_Cyrl"
        if "hf_split_default" not in st.session_state:
            st.session_state.hf_split_default = "train"
        
        # –ü—Ä–µ–¥–∑–∞–ø–æ–ª–Ω—è–µ–º –∫—ç—à –¥–ª—è –¥–µ—Ñ–æ–ª—Ç–Ω–æ–≥–æ –ø—Ä–µ—Å–µ—Ç–∞ (FineWeb-2)
        # —á—Ç–æ–±—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–≥ —Å—Ä–∞–∑—É —Å–∫–∞—á–∏–≤–∞—Ç—å –±–µ–∑ –Ω–∞–∂–∞—Ç–∏—è "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å"
        if "ds_repo_info" not in st.session_state:
            st.session_state.ds_repo_info = {}
        
        default_repo = "HuggingFaceFW/fineweb-2"
        if default_repo not in st.session_state.ds_repo_info:
            st.session_state.ds_repo_info[default_repo] = {
                "configs": ["rus_Cyrl"],  # –î–µ—Ñ–æ–ª—Ç–Ω—ã–π —è–∑—ã–∫
                "splits": ["train", "test"],  # –ò–∑–≤–µ—Å—Ç–Ω—ã–µ splits
                "features": {},  # –ó–∞–ø–æ–ª–Ω–∏—Ç—Å—è –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ
                "selected_config": "rus_Cyrl"
            }
        
        def on_preset_change():
            """Callback –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤—Å–µ—Ö –ø–æ–ª–µ–π –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –ø—Ä–µ—Å–µ—Ç–∞."""
            sel = st.session_state.dataset_preset_selector
            preset_data = presets.get(sel)
            if preset_data and preset_data[0]:
                st.session_state.hf_repo_id_input = preset_data[0]
                st.session_state.hf_subset_default = preset_data[1]
                st.session_state.hf_split_default = preset_data[2]
                
                # –°–±—Ä–∞—Å—ã–≤–∞–µ–º selectbox —á—Ç–æ–±—ã –ø—Ä–∏–º–µ–Ω–∏–ª–∏—Å—å –Ω–æ–≤—ã–µ –¥–µ—Ñ–æ–ª—Ç—ã
                if "hf_split_select" in st.session_state:
                    del st.session_state.hf_split_select
                if "hf_subset_select" in st.session_state:
                    del st.session_state.hf_subset_select

        # –°–µ–ª–µ–∫—Ç–æ—Ä –ø—Ä–µ—Å–µ—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é FineWeb-2 Russian)
        st.selectbox(
            "üìö –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã",
            options=list(presets.keys()),
            index=0,  # FineWeb-2 Russian –ø–µ—Ä–≤—ã–π
            key="dataset_preset_selector",
            on_change=on_preset_change,
            help="–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç ‚Äî –≤—Å–µ –ø–æ–ª—è –∑–∞–ø–æ–ª–Ω—è—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏"
        )

        repo_id = st.text_input("–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π (ID)", key="hf_repo_id_input")
        
        # –ö–Ω–æ–ø–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
        if st.button("üîç –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π"):
            try:
                with st.spinner(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {repo_id}..."):
                    # 1. –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥–∏
                    configs = get_dataset_config_names(repo_id)
                    
                    # 2. –í—ã–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ñ–∏–≥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è splits/features
                    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π (rus_Cyrl) > –ø–µ—Ä–≤—ã–π –≤ —Å–ø–∏—Å–∫–µ
                    default_subset = st.session_state.hf_subset_default
                    if default_subset in configs:
                        selected_config = default_subset
                    else:
                        selected_config = configs[0] if configs else None
                    
                    splits = []
                    features_info = {}
                    
                    if selected_config:
                        splits = get_dataset_split_names(repo_id, selected_config)
                        # 3. –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ (features)
                        try:
                            ds_builder = load_dataset_builder(repo_id, selected_config)
                            if ds_builder.info.features:
                                features_info = ds_builder.info.features
                        except Exception as e:
                            print(f"Could not load features: {e}")

                    st.session_state.ds_repo_info[repo_id] = {
                        "configs": configs,
                        "splits": splits,
                        "features": features_info,
                        "selected_config": selected_config  # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –¥–ª—è –∫–∞–∫–æ–≥–æ –∫–æ–Ω—Ñ–∏–≥–∞ splits
                    }
                    
                    # –í–ê–ñ–ù–û: –°–±—Ä–∞—Å—ã–≤–∞–µ–º –≤—ã–±–æ—Ä –≤–∏–¥–∂–µ—Ç–æ–≤ —á—Ç–æ–±—ã –ø—Ä–∏–º–µ–Ω–∏–ª–∏—Å—å –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                    if "hf_split_select" in st.session_state:
                        del st.session_state.hf_split_select
                    if "hf_subset_select" in st.session_state:
                        del st.session_state.hf_subset_select
                    
                    st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(configs)} –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π, splits: {splits}")
            except Exception as e:
                st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é: {e}")

        # –†–∞–±–æ—Ç–∞–µ–º —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        repo_info = st.session_state.ds_repo_info.get(repo_id, {})
        available_configs = repo_info.get("configs", [])
        available_splits = repo_info.get("splits", [])
        features = repo_info.get("features", {})
        
        if available_configs:
            # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π subset, –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –µ–≥–æ –≤ —Å–ø–∏—Å–∫–µ
            default_idx = 0
            if st.session_state.hf_subset_default in available_configs:
                default_idx = available_configs.index(st.session_state.hf_subset_default)
            subset = st.selectbox("Subset (–∫–æ–Ω—Ñ–∏–≥)", available_configs, index=default_idx, key="hf_subset_select")
        else:
            subset = st.text_input("Subset (–∫–æ–Ω—Ñ–∏–≥)", st.session_state.hf_subset_default, key="hf_subset_input")
        
        if available_splits:
            default_idx = 0
            if st.session_state.hf_split_default in available_splits:
                default_idx = available_splits.index(st.session_state.hf_split_default)
            split = st.selectbox("Split", available_splits, index=default_idx, key="hf_split_select")
        else:
            split = st.text_input("Split", st.session_state.hf_split_default, key="hf_split_input")

        # --- –£–ú–ù–´–ï –§–ò–õ–¨–¢–†–´ ---
        with st.expander("üõ†Ô∏è –§–∏–ª—å—Ç—Ä—ã –∏ –õ–∏–º–∏—Ç—ã", expanded=True):
            # –õ–∏–º–∏—Ç—ã (–≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–Ω—ã)
            col_lim1, col_lim2 = st.columns(2)
            with col_lim1:
                limit_type = st.radio("–¢–∏–ø –ª–∏–º–∏—Ç–∞", ["–ì–ë (–†–∞–∑–º–µ—Ä)", "–°—Ç—Ä–æ–∫–∏ (–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ)"], key="limit_type")
            
            with col_lim2:
                limit_val = 0
                limit_bytes = 0
                
                if limit_type == "–°—Ç—Ä–æ–∫–∏ (–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ)":
                    limit_val = st.number_input("–ö–æ–ª-–≤–æ —Å—Ç—Ä–æ–∫", value=100000, step=10000, key="limit_val")
                else:
                    limit_gb = st.number_input("–†–∞–∑–º–µ—Ä (–ì–ë)", value=2.0, step=0.5, min_value=0.1, key="limit_gb")
                    limit_bytes = int(limit_gb * 1024**3)
            
            st.divider()
            
            # –§–∏–ª—å—Ç—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (features)
            active_filters = {}
            
            if features:
                st.caption("üîç –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º:")
                
                # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –∏ –∏—Ö —Ç–∏–ø–æ–≤
                # features —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å {col_name: feature_info}
                # feature_info –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π 'Value(dtype='string')' –∏–ª–∏ –æ–±—ä–µ–∫—Ç–æ–º
                
                # 1. –§–∏–ª—å—Ç—Ä —á–∏—Å–ª–æ–≤–æ–π (Score/Quality)
                float_cols = []
                string_cols = []
                
                for col_name, feature_def in features.items():
                    # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø
                    dtype = getattr(feature_def, 'dtype', str(feature_def))
                    if 'float' in str(dtype):
                        float_cols.append(col_name)
                    elif 'string' in str(dtype):
                        string_cols.append(col_name)
                
                col_f1, col_f2 = st.columns(2)
                
                with col_f1:
                    if float_cols:
                        st.markdown("**–§–∏–ª—å—Ç—Ä –ø–æ –∑–Ω–∞—á–µ–Ω–∏—é (float)**")
                        selected_float_col = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É", ["(–Ω–µ—Ç)"] + float_cols, key="sel_float_col")
                        if selected_float_col != "(–Ω–µ—Ç)":
                            min_val = st.slider(f"–ú–∏–Ω. –∑–Ω–∞—á–µ–Ω–∏–µ {selected_float_col}", 0.0, 1.0, 0.0, key="val_float_col")
                            active_filters["score_col"] = selected_float_col
                            active_filters["min_score"] = min_val
                    else:
                        st.caption("–ß–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

                with col_f2:
                    if string_cols:
                        st.markdown("**–§–∏–ª—å—Ç—Ä –ø–æ —Ç–µ–∫—Å—Ç—É (contains)**")
                        selected_str_col = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É", ["(–Ω–µ—Ç)"] + string_cols, key="sel_str_col")
                        if selected_str_col != "(–Ω–µ—Ç)":
                            target_str = st.text_input(f"–¢–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å:", key="val_str_col")
                            if target_str:
                                active_filters["lang_col"] = selected_str_col
                                active_filters["target_lang"] = target_str
                    else:
                        st.caption("–¢–µ–∫—Å—Ç–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

            else:
                st.info("‚ö†Ô∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –î–æ—Å—Ç—É–ø–Ω—ã —Ç–æ–ª—å–∫–æ –ª–∏–º–∏—Ç—ã –ø–æ –æ–±—ä–µ–º—É.")


        save_filename = st.text_input("–ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è", "dataset.jsonl", key="save_filename")
        
        # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º callback
        def on_download_click(active_filters_map):
            # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ session_state —è–≤–Ω–æ
            r_id = st.session_state.get('hf_repo_id_input')
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º subset –∏ split
            if st.session_state.get('hf_subset_select'):
                sub = st.session_state.get('hf_subset_select')
            else:
                sub = st.session_state.get('hf_subset_input')
                
            if st.session_state.get('hf_split_select'):
                spl = st.session_state.get('hf_split_select')
            else:
                spl = st.session_state.get('hf_split_input')
                
            l_type = st.session_state.get('limit_type')
            l_val = st.session_state.get('limit_val')
            
            l_gb = st.session_state.get('limit_gb', 2.0)
            l_bytes = int(l_gb * 1024**3)

            s_path = st.session_state.get('save_filename')
            
            # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
            filters_to_pass = {}
            
            # 1. –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —Ñ–∏–ª—å—Ç—Ä—ã
            if active_filters_map:
                if "score_col" in active_filters_map:
                    filters_to_pass["score_col"] = active_filters_map["score_col"]
                    filters_to_pass["min_score"] = st.session_state.get("filter_score", 0.0)
                
                if "lang_col" in active_filters_map:
                    filters_to_pass["lang_col"] = active_filters_map["lang_col"]
                    filters_to_pass["target_lang"] = st.session_state.get("filter_lang", "ru")
            
            # 2. –§–æ–ª–±—ç–∫ –¥–ª—è FineWeb (—É–¥–∞–ª–µ–Ω, —Ç–∞–∫ –∫–∞–∫ –≤—ã–∑—ã–≤–∞–ª –ø—É—Ç–∞–Ω–∏—Ü—É)
            # elif "fineweb" in r_id.lower():
            #      pass
            
            download_hf_dataset(r_id, sub, spl, l_type, l_val, l_bytes, s_path, filters=filters_to_pass)

        st.button("–°–∫–∞—á–∞—Ç—å –∏ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å", on_click=on_download_click, args=(active_filters,))
    
    with col_list:
        st.subheader("–î–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã")
        
        datasets = []
        if DATASET_DIR.exists():
            # JSONL / JSON
            for f in list(DATASET_DIR.glob("*.jsonl")) + list(DATASET_DIR.glob("*.json")):
                size_mb = f.stat().st_size / (1024 * 1024)
                datasets.append({
                    "name": f.name,
                    "type": "JSONL/JSON",
                    "size_mb": size_mb,
                    "path": f
                })
            # TXT
            for f in DATASET_DIR.glob("*.txt"):
                size_mb = f.stat().st_size / (1024 * 1024)
                datasets.append({
                    "name": f.name,
                    "type": "Text",
                    "size_mb": size_mb,
                    "path": f
                })
        
        if not datasets:
            st.info("–ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã —Å–ª–µ–≤–∞.")
        else:
            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å–ø–∏—Å–æ–∫
            for ds in datasets:
                with st.expander(f"üìÑ {ds['name']} ({ds['size_mb']:.1f} MB)"):
                    st.caption(f"–¢–∏–ø: {ds['type']}")
                    
                    # Preview
                    try:
                        with open(ds['path'], "r", encoding="utf-8") as f:
                            head = [next(f).strip() for _ in range(5)]
                        st.markdown("**Preview (–ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫):**")
                        st.code("\n".join(head), language="json" if "JSON" in ds['type'] else "text")
                        
                        col_del, col_info = st.columns([1, 4])
                        with col_del:
                            if st.button("üóëÔ∏è –£–¥–∞–ª–∏—Ç—å", key=f"del_{ds['name']}"):
                                ds['path'].unlink()
                                st.toast(f"–§–∞–π–ª {ds['name']} —É–¥–∞–ª—ë–Ω", icon="üóëÔ∏è")
                                time.sleep(1)
                                st.rerun()
                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")


def calculate_memory_footprint(config, batch_size, distributed_mode="default", num_gpus=1):
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ VRAM (–≤ –ì–ë) –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.
    –£—á–∏—Ç—ã–≤–∞–µ—Ç: –≤–µ—Å–∞, –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä, –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏.
    """
    try:
        hidden_size = config["hidden_size"]
        num_layers = config["num_layers"]
        n_heads = config["n_heads"]
        seq_len = config["seq_len"]
        vocab_size = 50257  # –ü—Ä–∏–º–µ—Ä–Ω–æ –¥–ª—è GPT-2 / Llama
        
        # 1. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ (P)
        embed_params = vocab_size * hidden_size
        layer_params = 12 * hidden_size**2 + 13 * hidden_size # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞ –¥–ª—è –±–ª–æ–∫–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞
        total_params = embed_params + num_layers * layer_params
        
        # 2. –°—Ç–∞—Ç–∏—á–µ—Å–∫–∞—è –ø–∞–º—è—Ç—å (–í–µ—Å–∞ + –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã + –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä)
        # –ë–∞–∑–æ–≤–∞—è Mixed Precision (fp16/bf16):
        # - Weights (fp16): 2 bytes
        # - Gradients (fp16): 2 bytes
        # - Optimizer (AdamW):
        #    - FP32 Master weights: 4 bytes
        #    - Momentum (fp32): 4 bytes
        #    - Variance (fp32): 4 bytes
        # –ò—Ç–æ–≥–æ: ~16-18 –±–∞–π—Ç –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä.
        
        bytes_per_param = 18 
        
        # –£—á–µ—Ç Distributed —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        if "deepspeed_zero3" in distributed_mode:
            # ZeRO-3 —à–∞—Ä–¥–∏—Ä—É–µ—Ç –≤—Å–µ (–≤–µ—Å–∞, –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã, –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä)
            static_mem_bytes = (total_params * bytes_per_param) / max(1, num_gpus)
        elif "deepspeed_zero2" in distributed_mode:
            # ZeRO-2 —à–∞—Ä–¥–∏—Ä—É–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä (8+4+4=16 bytes), –Ω–æ –≤–µ—Å–∞ (2 bytes) –¥—É–±–ª–∏—Ä—É—é—Ç—Å—è
            sharded_part = (total_params * 16) / max(1, num_gpus)
            replicated_part = total_params * 2
            static_mem_bytes = sharded_part + replicated_part
        elif distributed_mode == "fsdp":
            # FSDP –ø–æ—Ö–æ–∂ –Ω–∞ ZeRO-3
            static_mem_bytes = (total_params * bytes_per_param) / max(1, num_gpus)
        else:
            # DDP –∏–ª–∏ Single GPU: –ø–æ–ª–Ω–∞—è –∫–æ–ø–∏—è —É –≤—Å–µ—Ö
            static_mem_bytes = total_params * bytes_per_param

        # 3. –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –ø–∞–º—è—Ç—å (–ê–∫—Ç–∏–≤–∞—Ü–∏–∏)
        # –ó–∞–≤–∏—Å–∏—Ç –æ—Ç Batch Size –∏ Seq Len.
        # –§–æ—Ä–º—É–ª–∞: Batch * Seq * Hidden * Layers * Bytes * Overhead_Factor
        # Overhead_Factor –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤ –±–µ–∑ checkpointing ~34 (—Ö—Ä–∞–Ω–∏–º –≤—Å–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è)
        # –° checkpointing ~4 (—Ö—Ä–∞–Ω–∏–º —Ç–æ–ª—å–∫–æ –≤—Ö–æ–¥—ã —Å–ª–æ–µ–≤ + –ø–µ—Ä–µ—Å—á–µ—Ç)
        
        overhead_factor = 4 if config.get("grad_checkpoint") else 34
        activation_bytes = batch_size * seq_len * hidden_size * num_layers * 2 * overhead_factor
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –ì–ë
        static_gb = static_mem_bytes / (1024**3)
        act_gb = activation_bytes / (1024**3)
        buffer_gb = 1.5  # –ë—É—Ñ–µ—Ä –¥–ª—è PyTorch context, cuda kernels fragmentation
        
        total_gb = static_gb + act_gb + buffer_gb
        
        return {
            "total_gb": round(total_gb, 2),
            "model_gb": round(static_gb, 2),
            "act_gb": round(act_gb, 2),
            "params": total_params
        }
    except Exception as e:
        print(f"Error calculating VRAM: {e}")
        return {"total_gb": 0, "model_gb": 0, "act_gb": 0, "params": 0}


def render_model_preview(config: dict, distributed_config: dict = None):
    """–ü—Ä–µ–≤—å—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏ –∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞."""
    st.subheader("üìê –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏")
    
    stage = config.get("stage", "pretrain")
    if stage == "sft":
        st.info(f"üîÑ **–†–µ–∂–∏–º SFT** (Fine-Tuning)\n–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: `{Path(config.get('base_model_path') or 'Unknown').name}`")
    else:
        st.success("üèóÔ∏è **–†–µ–∂–∏–º Pretraining** (–° –Ω—É–ª—è)")

    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–∞–º—è—Ç—å
    # –ù–∞–º –Ω—É–∂–µ–Ω batch_size –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ (—ç—Ç–æ –±–∞—Ç—á –Ω–∞ –¥–µ–≤–∞–π—Å)
    batch_size = config.get("batch_size", 1)
    dist_mode = distributed_config.get("distributed_mode", "default") if distributed_config else "default"
    n_gpus = distributed_config.get("num_gpus", 1) if distributed_config else 1
    
    mem_info = calculate_memory_footprint(config, batch_size, dist_mode, n_gpus)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Hidden Size", config["hidden_size"])
        st.metric("Layers", config["num_layers"])
    
    with col2:
        st.metric("Attention Heads", config["n_heads"])
        st.metric("Head Dim", config["hidden_size"] // config["n_heads"])
    
    with col3:
        st.metric("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã", format_params(mem_info["params"]))
        
        # –¶–≤–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ (–ø—Ä–∏–º–µ—Ä–Ω–æ –¥–ª—è 24GB –∫–∞—Ä—Ç—ã)
        val = mem_info["total_gb"]
        color = "normal"
        if val > 24: color = "off" # –∫—Ä–∞—Å–Ω—ã–π –æ—Ç—Ç–µ–Ω–æ–∫ –≤ –¥–µ–ª—å—Ç–µ –æ–±—ã—á–Ω–æ
        
        st.metric(
            "VRAM (Estimate)", 
            f"{val:.1f} GB", 
            delta=f"M: {mem_info['model_gb']} + A: {mem_info['act_gb']} GB",
            delta_color=color,
            help="M: Static Model Memory (Weights+Optim)\nA: Activations (Batch Size dependent)"
        )
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
    if mem_info["total_gb"] > 0:
        st.caption("üìä –ü—Ä–∏–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ GPU:")
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π –±–∞—Ä —á–∞—Ä—Ç —á–µ—Ä–µ–∑ HTML/CSS –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏
        total = mem_info["total_gb"]
        p_model = (mem_info["model_gb"] / total) * 100
        p_act = (mem_info["act_gb"] / total) * 100
        p_buff = 100 - p_model - p_act
        
        st.markdown(f"""
        <div style="display: flex; height: 20px; width: 100%; background: #333; border-radius: 4px; overflow: hidden; margin-top: 5px;">
            <div style="width: {p_model}%; background: #3b82f6; text-align: center; color: white; font-size: 10px; line-height: 20px;" title="Model & Optim">Model</div>
            <div style="width: {p_act}%; background: #e94560; text-align: center; color: white; font-size: 10px; line-height: 20px;" title="Activations">Act</div>
            <div style="width: {p_buff}%; background: #777; text-align: center; color: white; font-size: 10px; line-height: 20px;" title="Buffer">Buf</div>
        </div>
        <div style="display: flex; justify-content: space-between; font-size: 12px; color: #888; margin-top: 2px;">
            <span>Model + Optim: {mem_info['model_gb']} GB</span>
            <span>Activations: {mem_info['act_gb']} GB</span>
        </div>
        """, unsafe_allow_html=True)

        if mem_info["act_gb"] > mem_info["model_gb"] * 2:
            st.warning("‚ö†Ô∏è –ê–∫—Ç–∏–≤–∞—Ü–∏–∏ –∑–∞–Ω–∏–º–∞—é—Ç –º–Ω–æ–≥–æ –ø–∞–º—è—Ç–∏! –í–∫–ª—é—á–∏—Ç–µ Gradient Checkpointing –∏–ª–∏ —É–º–µ–Ω—å—à–∏—Ç–µ Batch Size.")

    
    # –í–∏–∑—É–∞–ª—å–Ω–∞—è —Å—Ö–µ–º–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
    st.markdown(f"""
    <div class="model-ascii">
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         HomeForCausalLM             ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ  Embedding: 50257 ‚Üí {config['hidden_size']:4d}           ‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
    ‚îÇ  ‚îÇ HomeBlock √ó {config['num_layers']:2d}              ‚îÇ    ‚îÇ
    ‚îÇ  ‚îÇ  ‚Ä¢ RMSNorm ‚Üí Attention      ‚îÇ    ‚îÇ
    ‚îÇ  ‚îÇ  ‚Ä¢ {config['n_heads']:2d} heads √ó {config['hidden_size']//config['n_heads']:3d} dim      ‚îÇ    ‚îÇ
    ‚îÇ  ‚îÇ  ‚Ä¢ RMSNorm ‚Üí FFN (SwiGLU)   ‚îÇ    ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
    ‚îÇ  RMSNorm ‚Üí LM Head                  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    </div>
        """, unsafe_allow_html=True)
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–µ

    if distributed_config:
        st.subheader("‚ö° –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º")
        
        mode = distributed_config.get("distributed_mode", "default")
        mode_info = PARALLEL_TYPES.get(mode, PARALLEL_TYPES["default"])
        num_gpus = distributed_config.get("num_gpus", 0)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("–†–µ–∂–∏–º", mode_info["name"])
        
        with col2:
            st.metric("–¢–∏–ø", mode_info["type"])
        
        with col3:
            if num_gpus > 0:
                st.metric("GPU", f"{num_gpus} —à—Ç.")
            else:
                st.metric("–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ", "CPU")
        
        # –°—Ö–µ–º–∞ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞
        if mode == "default":
            parallel_diagram = """
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      Single Device      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   Full Model      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Full Optimizer  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Full Gradients  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
"""
        elif mode == "multi_gpu":
            parallel_diagram = f"""
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Data Parallel ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  GPU 0  ‚îÇ  ‚îÇ  GPU 1  ‚îÇ  ...  ‚îÇ  GPU N  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Model   ‚îÇ  ‚îÇ Model   ‚îÇ       ‚îÇ Model   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ (copy)  ‚îÇ  ‚îÇ (copy)  ‚îÇ       ‚îÇ (copy)  ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ       ‚îÇ            ‚îÇ                 ‚îÇ      ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Sync Gradients ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
–ö–∞–∂–¥–∞—è GPU: –ø–æ–ª–Ω–∞—è –∫–æ–ø–∏—è –º–æ–¥–µ–ª–∏, —á–∞—Å—Ç—å –±–∞—Ç—á–∞
"""
        elif mode == "fsdp":
            parallel_diagram = f"""
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ FSDP (Fully Sharded) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  GPU 0  ‚îÇ  ‚îÇ  GPU 1  ‚îÇ  ...  ‚îÇ  GPU N  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Shard 0 ‚îÇ  ‚îÇ Shard 1 ‚îÇ       ‚îÇ Shard N ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Params  ‚îÇ  ‚îÇ Params  ‚îÇ       ‚îÇ Params  ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ       ‚îÇ            ‚îÇ                 ‚îÇ      ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ All-Gather for Forward ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ Reduce-Scatter Backward ‚îÄ‚îò       ‚îÇ
‚îÇ                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
–ú–æ–¥–µ–ª—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –º–µ–∂–¥—É GPU (—ç–∫–æ–Ω–æ–º–∏—è VRAM)
"""
        elif "deepspeed" in mode:
            if "zero3" in mode:
                parallel_diagram = f"""
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ DeepSpeed ZeRO-3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  GPU 0  ‚îÇ  ‚îÇ  GPU 1  ‚îÇ  ...  ‚îÇ  GPU N  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Params  ‚îÇ  ‚îÇ Params  ‚îÇ       ‚îÇ Params  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  1/N    ‚îÇ  ‚îÇ  1/N    ‚îÇ       ‚îÇ  1/N    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Optim   ‚îÇ  ‚îÇ Optim   ‚îÇ       ‚îÇ Optim   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  1/N    ‚îÇ  ‚îÇ  1/N    ‚îÇ       ‚îÇ  1/N    ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                              ‚îÇ
‚îÇ  {'+ CPU Offload (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞ CPU)' if 'offload' in mode else ''}          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
–í—Å—ë —à–∞—Ä–¥–∏—Ä–æ–≤–∞–Ω–æ: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —ç–∫–æ–Ω–æ–º–∏—è VRAM
"""
            else:
                parallel_diagram = f"""
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ DeepSpeed ZeRO-2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  GPU 0  ‚îÇ  ‚îÇ  GPU 1  ‚îÇ  ...  ‚îÇ  GPU N  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Full    ‚îÇ  ‚îÇ Full    ‚îÇ       ‚îÇ Full    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Model   ‚îÇ  ‚îÇ Model   ‚îÇ       ‚îÇ Model   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Optim/N ‚îÇ  ‚îÇ Optim/N ‚îÇ       ‚îÇ Optim/N ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã —à–∞—Ä–¥–∏—Ä–æ–≤–∞–Ω—ã
"""
        else:
            parallel_diagram = ""
        
        if parallel_diagram:
            st.markdown(f"""
<div class="model-ascii">
{parallel_diagram}
</div>
            """, unsafe_allow_html=True)


def export_model_to_hf(model, tokenizer, source_path: str):
    """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π HF —Ñ–æ—Ä–º–∞—Ç."""
    try:
        source = Path(source_path)
        # –°–æ–∑–¥–∞–µ–º –∏–º—è –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞: export_TIMESTAMP
        export_name = f"export_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # –ï—Å–ª–∏ —ç—Ç–æ —á–µ–∫–ø–æ–∏–Ω—Ç, —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä—è–¥–æ–º —Å –Ω–∏–º, –Ω–æ –≤ –æ—Ç–¥–µ–ª—å–Ω—É—é –ø–∞–ø–∫—É
        # out/model/run/checkpoint_X -> out/model/run/export_X
        if "checkpoint" in source.name:
            export_dir = source.parent / f"export_{source.name}"
        else:
            export_dir = source.parent / export_name
            
        export_dir.mkdir(parents=True, exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        model.save_pretrained(export_dir)
        tokenizer.save_pretrained(export_dir)
        
        return str(export_dir)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {e}")
        return None


# ============================================================================
# Main App
# ============================================================================

def main():
    render_header()
    
    # Sidebar configs
    model_config = render_model_config()
    st.session_state.current_model_name = model_config.get("model_name_input", "home_model")
    
    training_config = render_training_config()
    distributed_config = render_distributed_config()
    
    # –ü–µ—Ä–µ–¥–∞–µ–º stage –≤ dataset_config
    dataset_config = render_dataset_config(stage=model_config.get("stage", "pretrain"))
    
    output_config = render_output_config(st.session_state.current_model_name)
    
    # Merge configs
    full_config = {**model_config, **training_config, **dataset_config, **output_config}
    full_config["distributed_mode"] = distributed_config["distributed_mode"]
    full_config["num_gpus"] = distributed_config["num_gpus"]
    full_config["config_file"] = distributed_config["config_file"]
    
    # Main content
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["üöÄ –ó–∞–ø—É—Å–∫", "üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥", "üí¨ –ß–∞—Ç", "üìú –ò—Å—Ç–æ—Ä–∏—è", "üíæ –î–∞–Ω–Ω—ã–µ", "üìö –£—á–µ–±–Ω–∏–∫"])
    
    with tab1:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # –ü–µ—Ä–µ–¥–∞–µ–º full_config, —á—Ç–æ–±—ã –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –ø–∞–º—è—Ç–∏ –≤–∏–¥–µ–ª batch_size –∏ grad_checkpoint
            render_model_preview(full_config, distributed_config)
            
            # SFT Config (Main Area)
            if model_config.get("stage") == "sft" and dataset_config.get("data_path"):
                st.markdown("---")
                # –í—ã–∑—ã–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é (–¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω–∞ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∞, –≤—ã–∑–æ–≤–µ—Ç—Å—è –ø–æ—Å–ª–µ–¥–Ω—è—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è)
                sft_cfg = render_sft_main_config(dataset_config["data_path"])
                full_config.update(sft_cfg)
            
            st.subheader("üìã –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è")
            st.json(full_config)
        
        with col2:
            st.subheader("üéÆ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ")
            
            if st.session_state.training_active:
                if st.button("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å", type="primary"):
                    with st.spinner("–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É..."):
                        stopped = stop_training()
                    if stopped:
                        st.success("‚úÖ –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
                    else:
                        st.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å (–≤–æ–∑–º–æ–∂–Ω–æ —É–∂–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞)")
                    time.sleep(1)
                    st.rerun()
            else:
                if st.button("‚ñ∂Ô∏è –ù–∞—á–∞—Ç—å —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É", type="primary"):
                    with st.spinner("–ó–∞–ø—É—Å–∫..."):
                        run_id, process = start_training(full_config)
                        st.session_state.current_run_id = run_id
                        st.session_state.training_process = process
                        st.session_state.training_active = True
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–∫—Ç–∏–≤–Ω—ã–π run –¥–ª—è persistence
                        save_active_run(run_id, full_config)
                        
                        st.success(f"–¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –∑–∞–ø—É—â–µ–Ω–∞! Run ID: {run_id}")
                        time.sleep(1)
                        st.rerun()
    
    with tab2:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º fragment –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–µ–∑ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        live_metrics_fragment()
    
    with tab4:
        st.header("üìú –ò—Å—Ç–æ—Ä–∏—è –∑–∞–ø—É—Å–∫–æ–≤")
        st.markdown("---")
        
        runs = sorted(RUNS_DIR.glob("*"), reverse=True)
        
        if runs:
            for run_dir in runs[:10]:  # Last 10 runs
                run_id = run_dir.name
                metrics = load_metrics(run_id)
                
                if metrics:
                    status = metrics.get("status", "unknown")
                    status_emoji = {"training": "üü¢", "completed": "‚úÖ", "error": "‚ùå", "stopped": "‚èπÔ∏è"}.get(status, "‚è≥")
                    
                    with st.expander(f"{status_emoji} {run_id}"):
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("Steps", metrics.get("current_step", 0))
                        with col2:
                            st.metric("Final Loss", f"{metrics.get('current_loss', 0):.4f}")
                        with col3:
                            st.metric("Status", status)
                        with col4:
                            st.metric("Duration", metrics.get("training_duration", "-"))
                        
                        # –ß–µ–∫–ø–æ–∏–Ω—Ç—ã —ç—Ç–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
                        checkpoints = metrics.get("checkpoints", [])
                        if checkpoints:
                            st.markdown("**üì¶ –ß–µ–∫–ø–æ–∏–Ω—Ç—ã:**")
                            for ckpt in checkpoints[-5:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5
                                st.caption(f"Step {ckpt['step']}: `{ckpt['path']}`")
                        
                        # –ö–Ω–æ–ø–∫–∏
                        btn_col1, btn_col2 = st.columns(2)
                        with btn_col1:
                            if st.button(f"üìä –ú–µ—Ç—Ä–∏–∫–∏", key=f"metrics_{run_id}"):
                                st.session_state.current_run_id = run_id
                                st.toast(f"‚úÖ –í—ã–±—Ä–∞–Ω run: {run_id}. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –≤–∫–ª–∞–¥–∫—É üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥", icon="üìä")
                        with btn_col2:
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –º–æ–¥–µ–ª—å –¥–ª—è —á–∞—Ç–∞
                            config_path = run_dir / "config.json"
                            if config_path.exists():
                                try:
                                    with open(config_path) as f:
                                        run_config = json.load(f)
                                    model_dir = PROJECT_ROOT / run_config.get("output_dir", "")
                                    final_model = model_dir / "final_model"
                                    if final_model.exists():
                                        if st.button("üí¨ –ß–∞—Ç", key=f"chat_run_{run_id}"):
                                            st.session_state.selected_chat_model = str(final_model)
                                            st.toast("‚úÖ –ú–æ–¥–µ–ª—å –≤—ã–±—Ä–∞–Ω–∞! –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –≤–∫–ª–∞–¥–∫—É üí¨ –ß–∞—Ç", icon="üí¨")
                                except:
                                    pass
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –≤—ã–±—Ä–∞–Ω–æ
                        if st.session_state.current_run_id == run_id:
                            st.info("üëÜ –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –≤–∫–ª–∞–¥–∫—É **üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥**")
        else:
            st.info("–ù–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–∞–ø—É—Å–∫–æ–≤")
            
    with tab5:
        render_data_manager()
        
        # –ü–æ–¥—Å–∫–∞–∑–∫–∞ –ø—Ä–æ —á–∞—Ç
        st.markdown("---")
        st.info("üí° –ß—Ç–æ–±—ã –ø–æ–æ–±—â–∞—Ç—å—Å—è —Å –º–æ–¥–µ–ª—å—é, –ø–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –≤–∫–ª–∞–¥–∫—É **üí¨ –ß–∞—Ç** (–≤ –≤–µ—Ä—Ö–Ω–µ–π —á–∞—Å—Ç–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã)")

    with tab6:
        render_docs()
    
    with tab3:
        st.header("üí¨ –ß–∞—Ç —Å –º–æ–¥–µ–ª—å—é")
        st.markdown("---")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        available_models = get_available_models()
        
        if available_models:
            # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
            col1, col2 = st.columns([3, 1])
            
            with col1:
                model_options = [m["name"] for m in available_models]
                
                # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –≤—ã–±—Ä–∞–Ω–∞ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ - –Ω–∞—Ö–æ–¥–∏–º –µ—ë –∏–Ω–¥–µ–∫—Å
                default_idx = 0
                if st.session_state.selected_chat_model:
                    for i, m in enumerate(available_models):
                        if m["path"] == st.session_state.selected_chat_model:
                            default_idx = i
                            break
                
                selected_model_name = st.selectbox(
                    "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –∏–ª–∏ —á–µ–∫–ø–æ–∏–Ω—Ç",
                    options=model_options,
                    index=default_idx,
                    help="–í—ã–±–µ—Ä–∏—Ç–µ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è —á–∞—Ç–∞"
                )
                selected_model = next(m for m in available_models if m["name"] == selected_model_name)
                
                # –°–±—Ä–∞—Å—ã–≤–∞–µ–º selected_chat_model –ø–æ—Å–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                if st.session_state.selected_chat_model:
                    st.session_state.selected_chat_model = None
            
            with col2:
                model_type = selected_model["type"]
                if model_type == "final":
                    st.success("‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å")
                else:
                    st.info("üì¶ –ß–µ–∫–ø–æ–∏–Ω—Ç")
            
            st.caption(f"–ü—É—Ç—å: `{selected_model['path']}`")
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            with st.expander("‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"):
                gen_col1, gen_col2, gen_col3 = st.columns(3)
                with gen_col1:
                    max_tokens = st.slider("Max Tokens", 10, 500, 128)
                with gen_col2:
                    temperature = st.slider("Temperature", 0.1, 2.0, 0.8, 0.1)
                with gen_col3:
                    top_p = st.slider("Top-p", 0.1, 1.0, 0.9, 0.05)
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —á–∞—Ç–∞
            if "chat_model" not in st.session_state:
                st.session_state.chat_model = None
                st.session_state.chat_tokenizer = None
                st.session_state.chat_model_path = None
            
            if "messages" not in st.session_state:
                st.session_state.messages = []
            
            # –ö–Ω–æ–ø–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏
            if st.session_state.chat_model_path != selected_model["path"]:
                if st.button("üîÑ –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å", type="primary"):
                    with st.spinner("–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å..."):
                        try:
                            from transformers import AutoTokenizer
                            from homellm.models.home_model import HomeForCausalLM, HomeConfig
                            from safetensors.torch import load_file
                            
                            model_path = Path(selected_model["path"])
                            device = "cuda" if torch.cuda.is_available() else "cpu"
                            
                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —á–µ–∫–ø–æ–∏–Ω—Ç–∞
                            config_json = model_path / "config.json"
                            model_safetensors = model_path / "model.safetensors"
                            tokenizer_json = model_path / "tokenizer.json"
                            tokenizer_config = model_path / "tokenizer_config.json"
                            
                            # HuggingFace —Ñ–æ—Ä–º–∞—Ç = –µ—Å—Ç—å tokenizer —Ñ–∞–π–ª—ã
                            is_hf_format = tokenizer_json.exists() or tokenizer_config.exists()
                            
                            if is_hf_format and config_json.exists():
                                # HuggingFace —Ñ–æ—Ä–º–∞—Ç (final_model —Å tokenizer)
                                st.info("–ó–∞–≥—Ä—É–∂–∞–µ–º HuggingFace –º–æ–¥–µ–ª—å...")
                                st.session_state.chat_tokenizer = AutoTokenizer.from_pretrained(
                                    str(model_path), 
                                    trust_remote_code=True
                                )
                                st.session_state.chat_model = HomeForCausalLM.from_pretrained(
                                    str(model_path)
                                ).to(device)
                            elif model_safetensors.exists():
                                # Accelerate checkpoint —Ñ–æ—Ä–º–∞—Ç
                                st.info("–ó–∞–≥—Ä—É–∂–∞–µ–º Accelerate —á–µ–∫–ø–æ–∏–Ω—Ç...")
                                
                                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä GPT-2 (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
                                st.session_state.chat_tokenizer = AutoTokenizer.from_pretrained("gpt2")
                                if st.session_state.chat_tokenizer.pad_token is None:
                                    st.session_state.chat_tokenizer.add_special_tokens({"pad_token": "<|pad|>"})
                                
                                # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥ –º–æ–¥–µ–ª–∏ –∏–∑ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
                                if config_json.exists():
                                    config = HomeConfig.from_pretrained(str(model_path))
                                    st.info(f"–ö–æ–Ω—Ñ–∏–≥ –∑–∞–≥—Ä—É–∂–µ–Ω: hidden_size={config.hidden_size}, layers={config.num_hidden_layers}")
                                else:
                                    # –ò—â–µ–º –∫–æ–Ω—Ñ–∏–≥ –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (run config)
                                    run_config_path = model_path.parent / "run_config.json"
                                    if run_config_path.exists():
                                        import json as json_module
                                        with open(run_config_path) as f:
                                            run_cfg = json_module.load(f)
                                        config = HomeConfig(
                                            vocab_size=len(st.session_state.chat_tokenizer),
                                            hidden_size=run_cfg.get("hidden_size", 512),
                                            num_hidden_layers=run_cfg.get("num_layers", 8),
                                            num_attention_heads=run_cfg.get("n_heads", 8),
                                            max_position_embeddings=run_cfg.get("seq_len", 512),
                                        )
                                        st.info(f"–ö–æ–Ω—Ñ–∏–≥ –∏–∑ run_config: hidden_size={config.hidden_size}")
                                    else:
                                        st.warning("‚ö†Ô∏è config.json –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —á–µ–∫–ø–æ–∏–Ω—Ç–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
                                        config = HomeConfig(
                                            vocab_size=len(st.session_state.chat_tokenizer),
                                            hidden_size=512,
                                            num_hidden_layers=8,
                                            num_attention_heads=8,
                                            max_position_embeddings=512,
                                        )
                                
                                st.session_state.chat_model = HomeForCausalLM(config)
                                
                                # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
                                state_dict = load_file(str(model_safetensors))
                                missing, unexpected = st.session_state.chat_model.load_state_dict(state_dict, strict=False)
                                
                                # –£–º–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∫–ª—é—á–µ–π
                                if missing:
                                    # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º lm_head.weight, —Ç–∞–∫ –∫–∞–∫ –æ–Ω —Å–≤—è–∑–∞–Ω —Å embed_tokens
                                    real_missing = [k for k in missing if k != "lm_head.weight"]
                                    if real_missing:
                                        st.warning(f"‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ! –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤–µ—Å–∞: {real_missing[:5]}... (–≤—Å–µ–≥–æ {len(real_missing)})")
                                        logger.warning(f"Missing keys: {real_missing}")
                                    else:
                                        # –ï—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ lm_head, –∑–Ω–∞—á–∏—Ç –≤—Å–µ –æ–∫
                                        logger.info("Missing only lm_head.weight (expected for tied weights)")
                                
                                if unexpected:
                                    st.warning(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã –ª–∏—à–Ω–∏–µ –∫–ª—é—á–∏ –≤ —á–µ–∫–ø–æ–∏–Ω—Ç–µ: {unexpected[:5]}...")

                                # –Ø–≤–Ω–æ —Å–≤—è–∑—ã–≤–∞–µ–º –≤–µ—Å–∞ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏
                                if hasattr(st.session_state.chat_model, "tie_weights"):
                                    st.session_state.chat_model.tie_weights()
                                    
                                st.session_state.chat_model = st.session_state.chat_model.to(device)
                            else:
                                raise ValueError(f"–ù–µ –Ω–∞–π–¥–µ–Ω config.json –∏–ª–∏ model.safetensors –≤ {model_path}")
                            
                            st.session_state.chat_model.eval()
                            st.session_state.chat_model_path = str(model_path)
                            st.session_state.messages = []
                            st.success("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
                            st.rerun()
                        except Exception as e:
                            import traceback
                            st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
                            st.code(traceback.format_exc())
            else:
                st.success(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {selected_model_name}")
                
                # –ö–Ω–æ–ø–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ (–¥–ª—è —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –æ—Å–æ–±–µ–Ω–Ω–æ –ø–æ–ª–µ–∑–Ω–∞)
                if st.button("üíæ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ HF —Ñ–æ—Ä–º–∞—Ç", help="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–∫ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å (—Å –∫–æ–Ω—Ñ–∏–≥–æ–º –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–æ–º)"):
                    with st.spinner("–≠–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏..."):
                        export_path = export_model_to_hf(
                            st.session_state.chat_model, 
                            st.session_state.chat_tokenizer, 
                            st.session_state.chat_model_path
                        )
                        if export_path:
                            st.success(f"–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤:\n`{export_path}`")
                            time.sleep(2)
                            st.rerun() # –û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å —ç–∫—Å–ø–æ—Ä—Ç

                # --- –ò–ù–¢–ï–†–§–ï–ô–° –ß–ê–¢–ê –° –§–ò–ö–°–ò–†–û–í–ê–ù–ù–´–ú –°–ö–†–û–õ–õ–û–ú ---
                chat_container = st.container(height=500) # –ü—Ä–æ–∫—Ä—É—á–∏–≤–∞–µ–º—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
                
                with chat_container:
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞
                    for message in st.session_state.messages:
                        with st.chat_message(message["role"]):
                            st.write(message["content"])
                
                # –í–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–≤—Å–µ–≥–¥–∞ –≤–Ω–∏–∑—É)
                if prompt := st.chat_input("–í–≤–µ–¥–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ..."):
                    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                    st.session_state.messages.append({"role": "user", "content": prompt})
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä (–ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —é–∑–µ—Ä–∞ —Å—Ä–∞–∑—É)
                    with chat_container:
                        with st.chat_message("user"):
                            st.write(prompt)
                    
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
                    with chat_container: # –û—Ç–≤–µ—Ç —Ç–æ–∂–µ –ø–∏—à–µ–º –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
                        with st.chat_message("assistant"):
                            with st.spinner("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è..."):
                                try:
                                    tokenizer = st.session_state.chat_tokenizer
                                    model = st.session_state.chat_model
                                    device = next(model.parameters()).device
                                    
                                    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
                                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º chat_template –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å (–¥–ª—è SFT –º–æ–¥–µ–ª–µ–π)
                                    # –ò–Ω–∞—á–µ –ø—Ä–æ—Å—Ç–æ —Å–∫–ª–µ–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç (–¥–ª—è Pretrain –º–æ–¥–µ–ª–µ–π)
                                    
                                    # –ë–µ—Ä–µ–º –∏—Å—Ç–æ—Ä–∏—é + –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                                    conversation = st.session_state.messages # [{"role": "user", ...}, ...]
                                    
                                    if tokenizer.chat_template:
                                        # –î–ª—è SFT –º–æ–¥–µ–ª–∏: –ø—Ä–∏–º–µ–Ω—è–µ–º —à–∞–±–ª–æ–Ω —Å —Ç–µ–≥–∞–º–∏
                                        prompt_text = tokenizer.apply_chat_template(
                                            conversation, 
                                            tokenize=False, 
                                            add_generation_prompt=True
                                        )
                                    else:
                                        # –î–ª—è Base/Pretrain –º–æ–¥–µ–ª–∏: –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç
                                        # –û–±—ã—á–Ω–æ Base –º–æ–¥–µ–ª–∏ –Ω–µ –ø–æ–Ω–∏–º–∞—é—Ç –¥–∏–∞–ª–æ–≥, –Ω–æ –ø–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ —Å–ª–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø—Ä–æ–º–ø—Ç
                                        # –∏–ª–∏ –≤–µ—Å—å –¥–∏–∞–ª–æ–≥ —Ç–µ–∫—Å—Ç–æ–º
                                        prompt_text = ""
                                        for m in conversation:
                                            prompt_text += f"{m['role']}: {m['content']}\n"
                                        prompt_text += "assistant: "
                                    
                                    inputs = tokenizer(prompt_text, return_tensors="pt").to(device)
                                    
                                    with torch.no_grad():
                                        outputs = model.generate(
                                            **inputs,
                                            max_new_tokens=max_tokens,
                                            temperature=temperature,
                                            top_p=top_p,
                                            do_sample=True,
                                            pad_token_id=tokenizer.pad_token_id or tokenizer.eos_token_id,
                                            use_cache=False,  # –û—Ç–∫–ª—é—á–∞–µ–º KV-cache –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                                        )
                                    
                                    response = tokenizer.decode(
                                        outputs[0][inputs["input_ids"].shape[1]:], 
                                        skip_special_tokens=True
                                    )
                                    
                                    st.write(response)
                                    st.session_state.messages.append({"role": "assistant", "content": response})
                                except Exception as e:
                                    st.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
                
                # –ö–Ω–æ–ø–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —á–∞—Ç–∞
                if st.session_state.messages:
                    if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç"):
                        st.session_state.messages = []
                        st.rerun()
        else:
            st.info("–ù–µ—Ç –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É –≤–æ –≤–∫–ª–∞–¥–∫–µ '–ó–∞–ø—É—Å–∫'!")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≥–¥–µ –∏—Å–∫–∞—Ç—å –º–æ–¥–µ–ª–∏
            st.markdown("""
            **–ú–æ–¥–µ–ª–∏ –±—É–¥—É—Ç –¥–æ—Å—Ç—É–ø–Ω—ã –ø–æ—Å–ª–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏:**
            - `out/*/final_model/` ‚Äî —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏
            - `out/*/checkpoint_*/` ‚Äî —á–µ–∫–ø–æ–∏–Ω—Ç—ã
            """)


if __name__ == "__main__":
    main()


