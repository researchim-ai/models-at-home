"""
HomeLLM Training Studio â€” Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
======================================================================

Ğ—Ğ°Ğ¿ÑƒÑĞº:
    streamlit run homellm/app/main.py
    
Ğ¸Ğ»Ğ¸:
    ./scripts/run_studio.sh
"""

import streamlit as st
import subprocess
import json
import time
import os
import signal
from pathlib import Path
from datetime import datetime
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import pandas as pd

# ĞŸÑƒÑ‚Ğ¸
PROJECT_ROOT = Path(__file__).parent.parent.parent
CONFIGS_DIR = PROJECT_ROOT / "configs"
DATASET_DIR = PROJECT_ROOT / "datasets"  # datasets Ñ "s"!
OUTPUT_DIR = PROJECT_ROOT / "out"
RUNS_DIR = PROJECT_ROOT / ".runs"
RUNS_DIR.mkdir(exist_ok=True)

# ============================================================================
# Page Config
# ============================================================================

st.set_page_config(
    page_title="HomeLLM Training Studio",
    page_icon="ğŸ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS â€” Ñ‡Ğ¸ÑÑ‚Ğ°Ñ Ñ‚Ñ‘Ğ¼Ğ½Ğ°Ñ Ñ‚ĞµĞ¼Ğ° Ñ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¸Ğ¼ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ°ÑÑ‚Ğ¾Ğ¼
st.markdown("""
<style>
    /* Ğ—Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº */
    .main-header {
        color: #ff6b6b;
        font-size: 2.5rem;
        font-weight: 800;
        text-align: center;
        margin-bottom: 0.5rem;
    }
    
    .sub-header {
        color: #888888;
        text-align: center;
        font-size: 1.1rem;
        margin-bottom: 2rem;
    }
    
    /* Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ */
    .status-running {
        color: #22c55e !important;
        font-weight: bold;
    }
    
    .status-completed {
        color: #3b82f6 !important;
        font-weight: bold;
    }
    
    .status-error {
        color: #ef4444 !important;
        font-weight: bold;
    }
    
    /* ASCII art Ğ±Ğ»Ğ¾Ğº */
    .model-ascii {
        background: #1e1e1e;
        border: 1px solid #333;
        border-radius: 8px;
        padding: 1rem;
        font-family: 'Courier New', monospace;
        color: #00ff88;
        white-space: pre;
        overflow-x: auto;
    }
    
    /* ĞšĞ°Ñ€Ñ‚Ğ¾Ñ‡ĞºĞ¸ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº */
    div[data-testid="metric-container"] {
        background: rgba(255, 255, 255, 0.05);
        border: 1px solid rgba(255, 255, 255, 0.1);
        border-radius: 8px;
        padding: 0.5rem;
    }
    
    /* ĞšĞ½Ğ¾Ğ¿ĞºĞ¸ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° */
    .stButton > button[kind="primary"] {
        background: linear-gradient(90deg, #e94560, #ff6b6b);
        color: white !important;
        border: none;
        font-weight: 600;
    }
    
    /* Code Ğ±Ğ»Ğ¾ĞºĞ¸ */
    pre {
        background: #0d1117 !important;
        color: #c9d1d9 !important;
        border: 1px solid #30363d !important;
    }
    
    code {
        color: #79c0ff !important;
    }
</style>
""", unsafe_allow_html=True)


# ============================================================================
# Session State
# ============================================================================

if "training_process" not in st.session_state:
    st.session_state.training_process = None
if "current_run_id" not in st.session_state:
    st.session_state.current_run_id = None
if "training_active" not in st.session_state:
    st.session_state.training_active = False


# ============================================================================
# Helper Functions
# ============================================================================

def get_available_datasets():
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ¾Ğ²."""
    datasets = []
    if DATASET_DIR.exists():
        for f in DATASET_DIR.glob("*.jsonl"):
            size_mb = f.stat().st_size / (1024 * 1024)
            datasets.append((f.name, f"{size_mb:.1f} MB"))
        for f in DATASET_DIR.glob("*.txt"):
            size_mb = f.stat().st_size / (1024 * 1024)
            datasets.append((f.name, f"{size_mb:.1f} MB"))
    return datasets


def estimate_parameters(hidden_size: int, num_layers: int, vocab_size: int = 50257) -> int:
    """ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²."""
    # Embedding: vocab_size * hidden_size
    embed = vocab_size * hidden_size
    # Each layer: attention (4 * hidden^2) + FFN (8 * hidden^2) + norms
    per_layer = 4 * hidden_size ** 2 + 8 * hidden_size ** 2 + 2 * hidden_size
    # LM head is tied, so not counted
    total = embed + num_layers * per_layer
    return total


def format_params(n: int) -> str:
    """Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²."""
    if n >= 1e9:
        return f"{n/1e9:.2f}B"
    elif n >= 1e6:
        return f"{n/1e6:.1f}M"
    elif n >= 1e3:
        return f"{n/1e3:.1f}K"
    return str(n)


def format_time(seconds: float) -> str:
    """Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸."""
    if seconds < 60:
        return f"{seconds:.0f}s"
    elif seconds < 3600:
        return f"{seconds/60:.1f}m"
    else:
        return f"{seconds/3600:.1f}h"


def load_metrics(run_id: str) -> dict:
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¸Ğ· Ñ„Ğ°Ğ¹Ğ»Ğ°."""
    metrics_path = RUNS_DIR / run_id / "metrics.json"
    if metrics_path.exists():
        try:
            with open(metrics_path) as f:
                return json.load(f)
        except:
            pass
    return None


def start_training(config: dict) -> str:
    """Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²ĞºÑƒ Ğ² Ñ„Ğ¾Ğ½Ğµ."""
    run_id = datetime.now().strftime("%Y%m%d_%H%M%S")
    run_dir = RUNS_DIR / run_id
    run_dir.mkdir(parents=True, exist_ok=True)
    
    config_path = run_dir / "config.json"
    metrics_path = run_dir / "metrics.json"
    stdout_path = run_dir / "stdout.log"
    stderr_path = run_dir / "stderr.log"
    
    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³
    with open(config_path, "w") as f:
        json.dump(config, f, indent=2)
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ metrics Ñ„Ğ°Ğ¹Ğ»
    with open(metrics_path, "w") as f:
        json.dump({"status": "starting", "current_step": 0}, f)
    
    # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ñ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ² Ñ„Ğ°Ğ¹Ğ»Ñ‹
    cmd = [
        "python", "-m", "homellm.app.trainer_worker",
        "--config", str(config_path),
        "--metrics", str(metrics_path)
    ]
    
    stdout_file = open(stdout_path, "w")
    stderr_file = open(stderr_path, "w")
    
    process = subprocess.Popen(
        cmd,
        cwd=str(PROJECT_ROOT),
        stdout=stdout_file,
        stderr=stderr_file,
        start_new_session=True,  # ĞÑ‚Ğ´ĞµĞ»ÑĞµĞ¼ Ğ¾Ñ‚ Ñ€Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒÑĞºĞ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ°
    )
    
    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ PID Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°
    pid_path = run_dir / "pid"
    with open(pid_path, "w") as f:
        f.write(str(process.pid))
    
    return run_id, process


def stop_training():
    """ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²ĞºÑƒ."""
    if st.session_state.training_process:
        try:
            os.kill(st.session_state.training_process.pid, signal.SIGTERM)
        except:
            pass
        st.session_state.training_process = None
        st.session_state.training_active = False
    
    # Ğ¢Ğ°ĞºĞ¶Ğµ Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ ÑƒĞ±Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾ PID Ğ¸Ğ· Ñ„Ğ°Ğ¹Ğ»Ğ°
    if st.session_state.current_run_id:
        pid_path = RUNS_DIR / st.session_state.current_run_id / "pid"
        if pid_path.exists():
            try:
                with open(pid_path) as f:
                    pid = int(f.read().strip())
                os.kill(pid, signal.SIGTERM)
            except:
                pass


def is_process_running(run_id: str) -> bool:
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ, Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½ Ğ»Ğ¸ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ."""
    pid_path = RUNS_DIR / run_id / "pid"
    if not pid_path.exists():
        return False
    
    try:
        with open(pid_path) as f:
            pid = int(f.read().strip())
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ»Ğ¸ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ
        os.kill(pid, 0)
        return True
    except (ProcessLookupError, ValueError, FileNotFoundError):
        return False


# ============================================================================
# UI Components
# ============================================================================

def render_header():
    st.markdown("# ğŸ  HomeLLM Training Studio")
    st.caption("Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ Ğ´Ğ»Ñ Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´Ğ¾Ğ¼Ğ°")


def render_model_config():
    """ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² ÑĞ°Ğ¹Ğ´Ğ±Ğ°Ñ€Ğµ."""
    st.sidebar.header("ğŸ§  ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸")
    
    # ĞŸÑ€ĞµÑĞµÑ‚Ñ‹
    preset = st.sidebar.selectbox(
        "ĞŸÑ€ĞµÑĞµÑ‚",
        ["Tiny (25M)", "Small (80M)", "Medium (200M)", "Large (400M)", "Custom"],
        index=0
    )
    
    presets = {
        "Tiny (25M)": (512, 8, 8),
        "Small (80M)": (768, 12, 12),
        "Medium (200M)": (1024, 16, 16),
        "Large (400M)": (1280, 20, 20),
    }
    
    if preset != "Custom" and preset in presets:
        default_h, default_l, default_n = presets[preset]
    else:
        default_h, default_l, default_n = 512, 8, 8
    
    hidden_size = st.sidebar.slider(
        "Hidden Size", 
        min_value=128, 
        max_value=2048, 
        value=default_h, 
        step=64,
        help="Ğ Ğ°Ğ·Ğ¼ĞµÑ€Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞºÑ€Ñ‹Ñ‚Ğ¾Ğ³Ğ¾ ÑĞ»Ğ¾Ñ"
    )
    
    num_layers = st.sidebar.slider(
        "Num Layers", 
        min_value=2, 
        max_value=32, 
        value=default_l,
        help="ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ»Ğ¾Ñ‘Ğ² Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€Ğ°"
    )
    
    n_heads = st.sidebar.slider(
        "Attention Heads", 
        min_value=2, 
        max_value=32, 
        value=default_n,
        help="ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ³Ğ¾Ğ»Ğ¾Ğ² Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ"
    )
    
    seq_len = st.sidebar.selectbox(
        "Seq Length",
        [256, 512, 1024, 2048],
        index=1,
        help="ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ´Ğ»Ğ¸Ğ½Ğ° Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸"
    )
    
    # ĞÑ†ĞµĞ½ĞºĞ° Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²
    est_params = estimate_parameters(hidden_size, num_layers)
    st.sidebar.metric("ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ (â‰ˆ)", format_params(est_params))
    
    return {
        "hidden_size": hidden_size,
        "num_layers": num_layers,
        "n_heads": n_heads,
        "seq_len": seq_len,
    }


def render_training_config():
    """ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ² ÑĞ°Ğ¹Ğ´Ğ±Ğ°Ñ€Ğµ."""
    st.sidebar.header("âš™ï¸ ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ")
    
    batch_size = st.sidebar.slider(
        "Batch Size",
        min_value=1,
        max_value=64,
        value=16,
        help="Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ±Ğ°Ñ‚Ñ‡Ğ°"
    )
    
    grad_accum = st.sidebar.slider(
        "Gradient Accumulation",
        min_value=1,
        max_value=32,
        value=4,
        help="Ğ¨Ğ°Ğ³Ğ¸ Ğ½Ğ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ¸Ñ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ°"
    )
    
    st.sidebar.caption(f"Effective batch: {batch_size * grad_accum}")
    
    learning_rate = st.sidebar.select_slider(
        "Learning Rate",
        options=[1e-5, 3e-5, 5e-5, 1e-4, 3e-4, 5e-4, 1e-3],
        value=5e-4,
        format_func=lambda x: f"{x:.0e}"
    )
    
    warmup_steps = st.sidebar.number_input(
        "Warmup Steps",
        min_value=0,
        max_value=10000,
        value=1000
    )
    
    epochs = st.sidebar.number_input(
        "Epochs",
        min_value=1,
        max_value=10,
        value=1
    )
    
    mixed_precision = st.sidebar.selectbox(
        "Mixed Precision",
        ["no", "fp16", "bf16"],
        index=2,
        help="bf16 Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ Ğ´Ğ»Ñ Ampere+ GPU"
    )
    
    grad_checkpoint = st.sidebar.checkbox(
        "Gradient Checkpointing",
        value=False,
        help="Ğ­ĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ‚ VRAM, Ğ½Ğ¾ Ğ¼ĞµĞ´Ğ»ĞµĞ½Ğ½ĞµĞµ"
    )
    
    return {
        "batch_size": batch_size,
        "gradient_accumulation": grad_accum,
        "learning_rate": learning_rate,
        "warmup_steps": warmup_steps,
        "epochs": epochs,
        "mixed_precision": mixed_precision,
        "grad_checkpoint": grad_checkpoint,
    }


def render_dataset_config():
    """Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°."""
    st.sidebar.header("ğŸ“ Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚")
    
    datasets = get_available_datasets()
    
    if datasets:
        dataset_options = [f"{name} ({size})" for name, size in datasets]
        selected = st.sidebar.selectbox("Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚", dataset_options)
        selected_name = selected.split(" (")[0]
        data_path = str(DATASET_DIR / selected_name)
    else:
        st.sidebar.warning("Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚Ñ‹ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹ Ğ² dataset/")
        data_path = st.sidebar.text_input("ĞŸÑƒÑ‚ÑŒ Ğº Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ñƒ", "dataset/data.jsonl")
    
    return {"data_path": data_path}


def render_output_config():
    """ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ°."""
    st.sidebar.header("ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ")
    
    output_dir = st.sidebar.text_input(
        "Output Directory",
        value="out/training_run"
    )
    
    save_every = st.sidebar.number_input(
        "Save Every N Steps",
        min_value=100,
        max_value=50000,
        value=5000
    )
    
    log_every = st.sidebar.number_input(
        "Log Every N Steps",
        min_value=1,
        max_value=1000,
        value=10
    )
    
    return {
        "output_dir": output_dir,
        "save_every": save_every,
        "log_every": log_every,
        "tokenizer_path": "gpt2"
    }


def render_metrics_dashboard(metrics: dict):
    """Ğ”Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´ Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ."""
    
    status = metrics.get("status", "unknown")
    
    # Status indicator
    status_emoji = {
        "training": "ğŸŸ¢", 
        "completed": "âœ…", 
        "error": "âŒ",
        "initializing": "â³",
        "loading_tokenizer": "â³",
        "loading_dataset": "â³",
        "building_model": "â³",
        "saving_model": "ğŸ’¾",
    }.get(status, "â³")
    
    st.subheader(f"{status_emoji} Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ: {status.upper()}")
    
    # Metrics cards
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        current_step = metrics.get("current_step", 0)
        total_steps = metrics.get("total_steps", 1)
        progress = current_step / total_steps * 100 if total_steps > 0 else 0
        st.metric("ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ", f"{progress:.1f}%", f"Step {current_step}/{total_steps}")
    
    with col2:
        loss = metrics.get("current_loss", 0)
        st.metric("Loss", f"{loss:.4f}")
    
    with col3:
        lr = metrics.get("current_lr", 0)
        st.metric("Learning Rate", f"{lr:.2e}")
    
    with col4:
        eta = metrics.get("eta_seconds", 0)
        st.metric("ETA", format_time(eta))
    
    # Progress bar
    st.progress(min(progress / 100, 1.0))
    
    # Charts
    if metrics.get("loss_history"):
        col1, col2 = st.columns(2)
        
        with col1:
            # Loss chart
            fig_loss = go.Figure()
            fig_loss.add_trace(go.Scatter(
                x=metrics["steps_history"],
                y=metrics["loss_history"],
                mode='lines',
                name='Loss',
                line=dict(color='#e94560', width=2)
            ))
            fig_loss.update_layout(
                title="Training Loss",
                xaxis_title="Step",
                yaxis_title="Loss",
                template="plotly_dark",
                height=300,
                margin=dict(l=0, r=0, t=40, b=0)
            )
            st.plotly_chart(fig_loss, width="stretch")
        
        with col2:
            # LR chart
            fig_lr = go.Figure()
            fig_lr.add_trace(go.Scatter(
                x=metrics["steps_history"],
                y=metrics["lr_history"],
                mode='lines',
                name='LR',
                line=dict(color='#60a5fa', width=2)
            ))
            fig_lr.update_layout(
                title="Learning Rate Schedule",
                xaxis_title="Step",
                yaxis_title="LR",
                template="plotly_dark",
                height=300,
                margin=dict(l=0, r=0, t=40, b=0)
            )
            st.plotly_chart(fig_lr, width="stretch")
    
    # Checkpoints
    if metrics.get("checkpoints"):
        with st.expander("ğŸ“¦ Checkpoints"):
            for ckpt in metrics["checkpoints"]:
                st.text(f"Step {ckpt['step']}: {ckpt['path']}")
    
    # Error
    if metrics.get("error"):
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ°: {metrics['error']}")
    
    # Ğ›Ğ¾Ğ³Ğ¸ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ°
    if st.session_state.current_run_id:
        run_dir = RUNS_DIR / st.session_state.current_run_id
        stderr_path = run_dir / "stderr.log"
        stdout_path = run_dir / "stdout.log"
        
        with st.expander("ğŸ“‹ Ğ›Ğ¾Ğ³Ğ¸ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ°"):
            col1, col2 = st.columns(2)
            
            with col1:
                st.caption("stdout")
                if stdout_path.exists():
                    with open(stdout_path) as f:
                        content = f.read()[-2000:]  # ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 2000 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²
                        st.code(content if content else "(Ğ¿ÑƒÑÑ‚Ğ¾)", language=None)
            
            with col2:
                st.caption("stderr")
                if stderr_path.exists():
                    with open(stderr_path) as f:
                        content = f.read()[-2000:]
                        st.code(content if content else "(Ğ¿ÑƒÑÑ‚Ğ¾)", language=None)


def render_model_preview(config: dict):
    """ĞŸÑ€ĞµĞ²ÑŒÑ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸."""
    st.subheader("ğŸ“ ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸")
    
    params = estimate_parameters(config["hidden_size"], config["num_layers"])
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Hidden Size", config["hidden_size"])
        st.metric("Layers", config["num_layers"])
    
    with col2:
        st.metric("Attention Heads", config["n_heads"])
        st.metric("Head Dim", config["hidden_size"] // config["n_heads"])
    
    with col3:
        st.metric("ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹", format_params(params))
        vram_est = params * 4 / 1e9  # fp32
        st.metric("VRAM (â‰ˆ fp32)", f"{vram_est:.1f} GB")
    
    # Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ°Ñ ÑÑ…ĞµĞ¼Ğ° Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹
    st.markdown(f"""
<div class="model-ascii">
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         HomeForCausalLM             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Embedding: 50257 â†’ {config['hidden_size']:4d}           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ HomeBlock Ã— {config['num_layers']:2d}              â”‚    â”‚
â”‚  â”‚  â€¢ RMSNorm â†’ Attention      â”‚    â”‚
â”‚  â”‚  â€¢ {config['n_heads']:2d} heads Ã— {config['hidden_size']//config['n_heads']:3d} dim      â”‚    â”‚
â”‚  â”‚  â€¢ RMSNorm â†’ FFN (SwiGLU)   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  RMSNorm â†’ LM Head                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</div>
    """, unsafe_allow_html=True)


# ============================================================================
# Main App
# ============================================================================

def main():
    render_header()
    
    # Sidebar configs
    model_config = render_model_config()
    training_config = render_training_config()
    dataset_config = render_dataset_config()
    output_config = render_output_config()
    
    # Merge configs
    full_config = {**model_config, **training_config, **dataset_config, **output_config}
    
    # Main content
    tab1, tab2, tab3 = st.tabs(["ğŸš€ Ğ—Ğ°Ğ¿ÑƒÑĞº", "ğŸ“Š ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³", "ğŸ“œ Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ"])
    
    with tab1:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            render_model_preview(model_config)
            
            st.subheader("ğŸ“‹ ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ")
            st.json(full_config)
        
        with col2:
            st.subheader("ğŸ® Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ")
            
            if st.session_state.training_active:
                if st.button("â¹ï¸ ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ", type="primary"):
                    stop_training()
                    st.success("Ğ¢Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°")
                    st.rerun()
            else:
                if st.button("â–¶ï¸ ĞĞ°Ñ‡Ğ°Ñ‚ÑŒ Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²ĞºÑƒ", type="primary"):
                    with st.spinner("Ğ—Ğ°Ğ¿ÑƒÑĞº..."):
                        run_id, process = start_training(full_config)
                        st.session_state.current_run_id = run_id
                        st.session_state.training_process = process
                        st.session_state.training_active = True
                        st.success(f"Ğ¢Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½Ğ°! Run ID: {run_id}")
                        time.sleep(1)
                        st.rerun()
    
    with tab2:
        if st.session_state.current_run_id:
            run_id = st.session_state.current_run_id
            metrics = load_metrics(run_id)
            process_alive = is_process_running(run_id)
            
            # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ°
            if process_alive:
                st.success(f"ğŸŸ¢ ĞŸÑ€Ğ¾Ñ†ĞµÑÑ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½ (Run: {run_id})")
            else:
                if metrics and metrics.get("status") == "completed":
                    st.success(f"âœ… Ğ¢Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° (Run: {run_id})")
                elif metrics and metrics.get("status") == "error":
                    st.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° (Run: {run_id})")
                else:
                    st.warning(f"âš ï¸ ĞŸÑ€Ğ¾Ñ†ĞµÑÑ Ğ½Ğµ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½ (Run: {run_id})")
            
            if metrics:
                render_metrics_dashboard(metrics)
                
                # Auto-refresh Ğ¿Ğ¾ĞºĞ° Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ¶Ğ¸Ğ² Ğ¸Ğ»Ğ¸ ÑÑ‚Ğ°Ñ‚ÑƒÑ training
                if process_alive or metrics.get("status") in ["training", "initializing", "loading_tokenizer", "loading_dataset", "building_model"]:
                    time.sleep(2)
                    st.rerun()
            else:
                st.info("ĞĞ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº...")
                if process_alive:
                    time.sleep(1)
                    st.rerun()
        else:
            st.info("Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²ĞºÑƒ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€Ğ° Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº")
    
    with tab3:
        st.subheader("ğŸ“œ Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ²")
        
        runs = sorted(RUNS_DIR.glob("*"), reverse=True)
        
        if runs:
            for run_dir in runs[:10]:  # Last 10 runs
                run_id = run_dir.name
                metrics = load_metrics(run_id)
                
                if metrics:
                    status = metrics.get("status", "unknown")
                    status_emoji = {"training": "ğŸŸ¢", "completed": "âœ…", "error": "âŒ"}.get(status, "â³")
                    
                    with st.expander(f"{status_emoji} {run_id}"):
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("Steps", metrics.get("current_step", 0))
                        with col2:
                            st.metric("Final Loss", f"{metrics.get('current_loss', 0):.4f}")
                        with col3:
                            st.metric("Status", status)
                        
                        if st.button(f"Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ {run_id}", key=run_id):
                            st.session_state.current_run_id = run_id
                            st.rerun()
        else:
            st.info("ĞĞµÑ‚ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ñ… Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ²")


if __name__ == "__main__":
    main()

