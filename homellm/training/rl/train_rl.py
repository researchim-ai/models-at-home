#!/usr/bin/env python
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è reasoning –Ω–∞ GSM8K —Å GRPO.

–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
    # –ë–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ
    python -m homellm.training.rl.train_rl --model Qwen/Qwen2.5-0.5B-Instruct

    # –° –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    python -m homellm.training.rl.train_rl \
        --model Qwen/Qwen2.5-1.5B-Instruct \
        --algorithm drgrpo \
        --batch_size 4 \
        --group_size 8 \
        --max_samples 1000 \
        --output_dir ./output/grpo

    # –° W&B –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    python -m homellm.training.rl.train_rl \
        --model Qwen/Qwen2.5-0.5B-Instruct \
        --use_wandb \
        --wandb_project my-grpo-experiments
"""
import argparse
import logging
from pathlib import Path
from datetime import datetime

from .legacy_config import GRPOConfig, RLAlgorithm
from .trainer import GRPOTrainer
from .data.gsm8k import load_gsm8k
from .rewards.base import CombinedReward, UniversalRuleReward
from .rewards.math import GSM8KReward
from .rewards.format import FormatReward, ReasoningQualityReward

logger = logging.getLogger(__name__)


def parse_args():
    """–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏."""
    parser = argparse.ArgumentParser(
        description="–û–±—É—á–µ–Ω–∏–µ LLM reasoning –Ω–∞ GSM8K —Å GRPO",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    
    # –ú–æ–¥–µ–ª—å
    parser.add_argument(
        "--model",
        type=str,
        default="Qwen/Qwen2.5-0.5B-Instruct",
        help="–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ HuggingFace –∏–ª–∏ –ø—É—Ç—å",
    )
    
    # –ê–ª–≥–æ—Ä–∏—Ç–º
    parser.add_argument(
        "--algorithm",
        type=str,
        default="grpo",
        choices=["grpo", "drgrpo", "dapo", "sdpo"],
        help="–ê–ª–≥–æ—Ä–∏—Ç–º RL",
    )
    parser.add_argument(
        "--preset",
        type=str,
        default=None,
        choices=["grpo", "drgrpo", "dapo", "sdpo", "reasoning_small", "reasoning_large"],
        help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é",
    )
    
    # –î–∞—Ç–∞—Å–µ—Ç
    parser.add_argument(
        "--max_samples",
        type=int,
        default=None,
        help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ (None = –≤–µ—Å—å –¥–∞—Ç–∞—Å–µ—Ç)",
    )
    parser.add_argument(
        "--split",
        type=str,
        default="train",
        choices=["train", "test"],
        help="Split –¥–∞—Ç–∞—Å–µ—Ç–∞",
    )
    parser.add_argument(
        "--dataset_file",
        type=str,
        default=None,
        help="–ü—É—Ç—å –∫ JSONL —Ñ–∞–π–ª—É –≤–º–µ—Å—Ç–æ GSM8K (–ø–æ–ª—è: prompt, answer)",
    )
    
    # Batch —Ä–∞–∑–º–µ—Ä—ã
    parser.add_argument(
        "--batch_size",
        type=int,
        default=4,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–º–ø—Ç–æ–≤ –Ω–∞ —à–∞–≥",
    )
    parser.add_argument(
        "--group_size",
        type=int,
        default=8,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–π –Ω–∞ –ø—Ä–æ–º–ø—Ç",
    )
    parser.add_argument(
        "--train_batch_size",
        type=int,
        default=2,
        help="Batch size –¥–ª—è –æ–±—É—á–µ–Ω–∏—è",
    )
    parser.add_argument(
        "--gradient_accumulation",
        type=int,
        default=4,
        help="–®–∞–≥–æ–≤ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞",
    )
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
    parser.add_argument(
        "--max_new_tokens",
        type=int,
        default=512,
        help="–ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ",
    )
    parser.add_argument(
        "--temperature",
        type=float,
        default=0.7,
        help="–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è",
    )
    
    # –û–±—É—á–µ–Ω–∏–µ
    parser.add_argument(
        "--learning_rate",
        type=float,
        default=5e-6,
        help="Learning rate",
    )
    parser.add_argument(
        "--num_epochs",
        type=int,
        default=1,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö",
    )
    parser.add_argument(
        "--max_steps",
        type=int,
        default=None,
        help="–ú–∞–∫—Å–∏–º—É–º —à–∞–≥–æ–≤ (None = –ø–æ —ç–ø–æ—Ö–∞–º)",
    )
    
    # GRPO –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument(
        "--clip_eps",
        type=float,
        default=0.2,
        help="Epsilon –¥–ª—è PPO –∫–ª–∏–ø–ø–∏–Ω–≥–∞",
    )
    parser.add_argument(
        "--kl_weight",
        type=float,
        default=0.0,
        help="–í–µ—Å KL —à—Ç—Ä–∞—Ñ–∞ (0 –¥–ª—è reasoning)",
    )
    
    # LoRA
    parser.add_argument(
        "--use_lora",
        action="store_true",
        default=True,
        help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LoRA",
    )
    parser.add_argument(
        "--no_lora",
        action="store_true",
        help="–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LoRA",
    )
    parser.add_argument(
        "--lora_r",
        type=int,
        default=16,
        help="LoRA rank",
    )
    
    # –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è
    parser.add_argument(
        "--use_4bit",
        action="store_true",
        help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 4-bit –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é",
    )
    parser.add_argument(
        "--use_8bit",
        action="store_true",
        help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 8-bit –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é",
    )
    
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    parser.add_argument(
        "--output_dir",
        type=str,
        default=None,
        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (auto –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ)",
    )
    parser.add_argument(
        "--save_steps",
        type=int,
        default=100,
        help="–°–æ—Ö—Ä–∞–Ω—è—Ç—å –∫–∞–∂–¥—ã–µ N —à–∞–≥–æ–≤",
    )
    parser.add_argument(
        "--log_steps",
        type=int,
        default=10,
        help="–õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–µ N —à–∞–≥–æ–≤",
    )
    parser.add_argument(
        "--use_wandb",
        action="store_true",
        help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å W&B",
    )
    parser.add_argument(
        "--wandb_project",
        type=str,
        default="homellm-grpo",
        help="–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ W&B",
    )
    
    # –§–æ—Ä–º–∞—Ç
    parser.add_argument(
        "--reasoning_format",
        type=str,
        default="deepseek",
        choices=["deepseek", "simple", "russian"],
        help="–§–æ—Ä–º–∞—Ç reasoning —Ç–µ–≥–æ–≤",
    )
    
    # –†–∞–∑–Ω–æ–µ
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="Random seed",
    )
    
    # JSON –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (–¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏–∑ Streamlit UI)
    parser.add_argument(
        "--config_json",
        type=str,
        default=None,
        help="JSON —Å—Ç—Ä–æ–∫–∞ —Å –ø–æ–ª–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π (–ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –¥—Ä—É–≥–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)",
    )
    
    return parser.parse_args()


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    import json
    
    args = parse_args()
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(
        level=logging.INFO,
        format="[%(asctime)s] [%(levelname)s] %(name)s | %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
    )
    
    logger.info("=" * 60)
    logger.info("GRPO Training –Ω–∞ GSM8K")
    logger.info("=" * 60)
    
    # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω–∞ JSON –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (–∏–∑ Streamlit UI)
    ui_config = None
    reward_rules = None
    
    if args.config_json:
        logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ JSON...")
        ui_config = json.loads(args.config_json)
        
        # === Unsloth Backend ===
        training_backend = ui_config.get("training_backend", "models-at-home")
        if training_backend == "unsloth":
            logger.info("ü¶• Using Unsloth backend for GRPO training")
            try:
                from homellm.training.unsloth_grpo import run_unsloth_grpo, is_unsloth_available
                
                if is_unsloth_available():
                    # –°–æ–∑–¥–∞—ë–º –ø—Ä–æ—Å—Ç–æ–π metrics logger
                    from pathlib import Path
                    import time
                    
                    ui_run_dir = ui_config.get("ui_run_dir")
                    if ui_run_dir:
                        metrics_path = Path(ui_run_dir) / "metrics.json"
                    else:
                        metrics_path = Path(ui_config.get("output_dir", "out/grpo")) / "metrics.json"
                    
                    class SimpleMetricsLogger:
                        def __init__(self, path):
                            self.path = Path(path)
                            self.start_ts = time.time()
                            self.metrics = {
                                "status": "initializing", 
                                "start_time": datetime.now().isoformat(),
                                "elapsed_seconds": 0.0,
                                "eta_seconds": 0.0,
                                "steps_history": [],
                                "loss_history": [],
                                "lr_history": [],
                                "reward_history": [],
                                "kl_history": [],
                            }
                            self._save()
                        
                        def _save(self):
                            self.path.parent.mkdir(parents=True, exist_ok=True)
                            with open(self.path, "w") as f:
                                json.dump(self.metrics, f, indent=2)
                        
                        def update(self, **kwargs):
                            self.metrics.update(kwargs)
                            self._save()
                        
                        def log_step(self, step, loss, lr, samples_per_sec=0, reward=None, kl=None):
                            self.metrics["current_step"] = step
                            self.metrics["current_loss"] = loss
                            self.metrics["current_lr"] = lr
                            self.metrics["samples_per_second"] = samples_per_sec
                            elapsed = max(0.0, time.time() - self.start_ts)
                            self.metrics["elapsed_seconds"] = elapsed
                            total_steps = self.metrics.get("total_steps")
                            if samples_per_sec and total_steps:
                                try:
                                    remaining_steps = max(0.0, float(total_steps) - float(step))
                                    self.metrics["eta_seconds"] = remaining_steps / float(samples_per_sec)
                                except Exception:
                                    pass
                            
                            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
                            self.metrics["steps_history"].append(step)
                            self.metrics["loss_history"].append(loss)
                            self.metrics["lr_history"].append(lr)
                            
                            # GRPO —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                            if reward is not None:
                                self.metrics["current_reward"] = reward
                                self.metrics["reward_history"].append(reward)
                            if kl is not None:
                                self.metrics["current_kl"] = kl
                                self.metrics["kl_history"].append(kl)
                            
                            self._save()
                        
                        def log_checkpoint(self, path):
                            if "checkpoints" not in self.metrics:
                                self.metrics["checkpoints"] = []
                            self.metrics["checkpoints"].append({"path": path, "step": self.metrics.get("current_step", 0)})
                            self._save()
                    
                    metrics_logger = SimpleMetricsLogger(metrics_path)
                    run_unsloth_grpo(ui_config, metrics_logger)
                    return  # –£—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ
                else:
                    logger.warning("‚ö†Ô∏è Unsloth not available, falling back to models-at-home backend")
            except ImportError as e:
                logger.warning(f"‚ö†Ô∏è Could not import unsloth_grpo: {e}. Falling back to models-at-home backend.")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º reward –ø—Ä–∞–≤–∏–ª–∞
        reward_rules = ui_config.get("grpo_reward_rules", [])
        if reward_rules:
            logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(reward_rules)} reward –ø—Ä–∞–≤–∏–ª –∏–∑ UI")
    
    # –°–æ–∑–¥–∞—ë–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    if args.preset:
        logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º preset: {args.preset}")
        config = GRPOConfig.from_preset(args.preset)
    else:
        algorithm = args.algorithm
        if ui_config:
            algorithm = ui_config.get("grpo_algorithm", algorithm)
        config = GRPOConfig(
            algorithm=RLAlgorithm(algorithm),
        )
    
    # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ UI –∫–æ–Ω—Ñ–∏–≥–∞
    # –í–ê–ñ–ù–û: –í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —è–≤–Ω–æ –ø–µ—Ä–µ–¥–∞–Ω—ã –∏–∑ UI, –±–µ–∑ fallback –Ω–∞ args
    # –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç —á—Ç–æ –º—ã —Ç–æ—á–Ω–æ –∑–Ω–∞–µ–º –æ—Ç–∫—É–¥–∞ –±–µ—Ä—É—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏—è
    if ui_config:
        # GRPO –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∏–∑ UI)
        if "grpo_prompt_batch_size" not in ui_config:
            raise ValueError("‚ùå –ù–µ –∑–∞–¥–∞–Ω grpo_prompt_batch_size (prompts/step) –∏–∑ UI.")
        config.batch_size = ui_config["grpo_prompt_batch_size"]

        config.group_size = ui_config["grpo_group_size"]
        if config.group_size < 8:
            raise ValueError("‚ùå group_size –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å >= 8 –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ GRPO.")

        config.train_batch_size = ui_config["grpo_train_batch_size"]
        config.gradient_accumulation_steps = ui_config["gradient_accumulation"]
        config.max_new_tokens = ui_config["grpo_max_new_tokens"]
        config.temperature = ui_config["grpo_temperature"]
        config.learning_rate = ui_config["grpo_learning_rate"]
        config.min_lr_ratio = float(ui_config.get("grpo_min_lr_ratio", getattr(config, "min_lr_ratio", 0.0)))
        # –õ–∏–º–∏—Ç—ã –æ–±—É—á–µ–Ω–∏—è:
        # - max_prompts: "—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –ø—Ä–æ–π—Ç–∏" (–ø–æ–Ω—è—Ç–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é)
        # - max_steps: legacy –ª–∏–º–∏—Ç –ø–æ optimizer steps (–µ—Å–ª–∏ –∫—Ç–æ-—Ç–æ –µ—â—ë –ø–µ—Ä–µ–¥–∞—ë—Ç —Å—Ç–∞—Ä—ã–π –∫–ª—é—á)
        config.max_prompts = ui_config.get("grpo_max_prompts", None)
        config.max_steps = ui_config.get("grpo_max_optim_steps", ui_config.get("grpo_max_steps", None))
        config.clip_eps_low = ui_config["grpo_clip_eps_low"]
        config.clip_eps_high = ui_config.get("grpo_clip_eps_high", config.clip_eps_low)
        config.kl_weight = ui_config["grpo_kl_weight"]
        config.epochs_per_step = ui_config.get("grpo_epochs_per_step", 1)
        config.reasoning_format = ui_config.get("grpo_reasoning_format", config.reasoning_format)
        # Precision –¥–æ–ª–∂–µ–Ω –ø—Ä–∏—Ö–æ–¥–∏—Ç—å –∏–∑ UI (render_distributed_config -> full_config -> config_json)
        config.mixed_precision = (ui_config.get("mixed_precision") or config.mixed_precision)
        config.fp16_pure = bool(ui_config.get("fp16_pure", getattr(config, "fp16_pure", False)))
        config.use_flash_attention = bool(ui_config.get("use_flash_attention", getattr(config, "use_flash_attention", True)))
        # Memory: gradient checkpointing –¥–æ–ª–∂–µ–Ω –ø—Ä–∏—Ö–æ–¥–∏—Ç—å –∏–∑ UI
        config.grad_checkpoint = bool(ui_config.get("grad_checkpoint", False))

        # Liger Kernel –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ ‚Äî –±–µ—Ä—ë–º –∏–∑ –æ–±—â–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫ Precision & Memory
        config.use_liger = bool(ui_config.get("use_liger", getattr(config, "use_liger", True)))
        config.liger_patch_model = config.use_liger  # –í—Å–µ–≥–¥–∞ –ø–∞—Ç—á–∏–º –µ—Å–ª–∏ Liger –≤–∫–ª—é—á—ë–Ω
        config.liger_chunk_size = 4096  # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä
        
        # üî• Liger Fused GRPO Loss ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –µ—Å–ª–∏ use_liger –∏ liger_fused_ce –≤–∫–ª—é—á–µ–Ω—ã
        liger_fused = bool(ui_config.get("liger_fused_ce", True))  # Fused Loss –∏–∑ –æ–±—â–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫
        config.liger_fused_grpo = config.use_liger and liger_fused
        
        # Loss type –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ (grpo‚Üígrpo, dapo‚Üídapo, drgrpo‚Üídr_grpo)
        config.liger_grpo_loss_type = ui_config.get("grpo_liger_loss_type", getattr(config, "liger_grpo_loss_type", "dapo"))

        # DAPO-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (UI –º–æ–∂–µ—Ç –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–µ—Ñ–æ–ª—Ç—ã –∏–∑ __post_init__)
        if "grpo_dynamic_sampling" in ui_config:
            config.dynamic_sampling = bool(ui_config["grpo_dynamic_sampling"])
        if "grpo_max_refill_rounds" in ui_config:
            config.max_refill_rounds = int(ui_config["grpo_max_refill_rounds"])
        if "grpo_token_level_loss" in ui_config:
            config.token_level_loss = bool(ui_config["grpo_token_level_loss"])
        
        # üéì SDPO-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        if "sdpo_success_threshold" in ui_config:
            config.sdpo_success_threshold = float(ui_config["sdpo_success_threshold"])
        if "sdpo_alpha" in ui_config:
            config.sdpo_alpha = float(ui_config["sdpo_alpha"])
        if "sdpo_loss_weight" in ui_config:
            config.sdpo_loss_weight = float(ui_config["sdpo_loss_weight"])
        # üî• SDPO Top-K Distillation –∏ EMA (–∏–∑ verl)
        if "sdpo_distillation_topk" in ui_config:
            topk = ui_config["sdpo_distillation_topk"]
            config.sdpo_distillation_topk = int(topk) if topk is not None else None
        if "sdpo_full_logit_distillation" in ui_config:
            config.sdpo_full_logit_distillation = bool(ui_config["sdpo_full_logit_distillation"])
        if "sdpo_ema_rate" in ui_config:
            config.sdpo_ema_rate = float(ui_config["sdpo_ema_rate"])

        # Rollout engine (–æ—Ç–¥–µ–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏)
        config.use_rollout_engine = bool(ui_config.get("grpo_use_rollout_engine", getattr(config, "use_rollout_engine", False)))
        config.rollout_engine_backend = ui_config.get("grpo_rollout_backend", getattr(config, "rollout_engine_backend", "hf"))
        config.rollout_sync_interval = int(ui_config.get("grpo_rollout_sync_interval", getattr(config, "rollout_sync_interval", 1)))
        config.rollout_sync_trainable_only = bool(ui_config.get("grpo_rollout_trainable_only", getattr(config, "rollout_sync_trainable_only", True)))
        config.rollout_offload_to_cpu = bool(ui_config.get("grpo_rollout_offload_to_cpu", getattr(config, "rollout_offload_to_cpu", False)))
        config.vllm_gpu_memory_utilization = float(ui_config.get("grpo_vllm_gpu_memory", getattr(config, "vllm_gpu_memory_utilization", 0.85)))
        config.vllm_device = ui_config.get("grpo_vllm_device", getattr(config, "vllm_device", "main_gpu"))

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ/–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (–∏–∑ UI output_config)
        config.save_steps = int(ui_config.get("save_every", config.save_steps))
        config.log_steps = int(ui_config.get("log_every", config.log_steps))
        config.export_on_checkpoint = bool(ui_config.get("export_on_checkpoint", config.export_on_checkpoint))
        config.merge_lora = bool(ui_config.get("merge_lora", True))  # Merge LoRA –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ final_model

        # –ü—É—Ç—å –¥–æ run_dir, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–∑–¥–∞–ª UI (–¥–ª—è "–∂–µ–ª–µ–∑–Ω–æ–≥–æ" –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞).
        # –ï—Å–ª–∏ –∑–∞–¥–∞–Ω, trainer –±—É–¥–µ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å metrics/samples –≤ —ç—Ç—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é.
        config.ui_run_dir = ui_config.get("ui_run_dir", ui_config.get("run_dir", None))
        
        # LoRA –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∏–∑ UI, –µ—Å–ª–∏ use_lora=True)
        config.use_lora = ui_config.get("use_lora", config.use_lora)
        if config.use_lora:
            # –í–ê–ñ–ù–û: –ï—Å–ª–∏ use_lora=True, –≤—Å–µ LoRA –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —è–≤–Ω–æ —É–∫–∞–∑–∞–Ω—ã –≤ UI
            if "lora_r" not in ui_config or ui_config["lora_r"] is None:
                raise ValueError(
                    "‚ùå use_lora=True –Ω–æ lora_r –Ω–µ —É–∫–∞–∑–∞–Ω –≤ UI –∫–æ–Ω—Ñ–∏–≥–µ! "
                    "–£–∫–∞–∂–∏—Ç–µ lora_r –≤ render_grpo_sidebar_config() –∏–ª–∏ –≤ model_config."
                )
            config.lora_r = ui_config["lora_r"]
            
            if "lora_alpha" not in ui_config or ui_config["lora_alpha"] is None:
                raise ValueError(
                    "‚ùå use_lora=True –Ω–æ lora_alpha –Ω–µ —É–∫–∞–∑–∞–Ω –≤ UI –∫–æ–Ω—Ñ–∏–≥–µ! "
                    "–£–∫–∞–∂–∏—Ç–µ lora_alpha –≤ render_grpo_sidebar_config() –∏–ª–∏ –≤ model_config."
                )
            config.lora_alpha = ui_config["lora_alpha"]
            
            # lora_dropout –∏ lora_target_modules –º–æ–≥—É—Ç –±—ã—Ç—å None (–∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç—ã –∏–∑ GRPOConfig)
            config.lora_dropout = ui_config.get("lora_dropout", config.lora_dropout)
            config.lora_target_modules = ui_config.get("lora_target_modules", config.lora_target_modules)
        
        # –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∏–∑ UI)
        config.use_4bit = ui_config.get("use_4bit", False)
        config.use_8bit = ui_config.get("use_8bit", False)
        config.quantize_reference_model = ui_config.get("quantize_reference_model", config.quantize_reference_model)
        
        # Output –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
        config.output_dir = ui_config.get("output_dir", f"./output/grpo_gsm8k/{datetime.now().strftime('%Y%m%d_%H%M%S')}")
    else:
        config.batch_size = args.batch_size
        config.group_size = args.group_size
        config.train_batch_size = args.train_batch_size
        config.gradient_accumulation_steps = args.gradient_accumulation
        config.max_new_tokens = args.max_new_tokens
        config.temperature = args.temperature
        config.learning_rate = args.learning_rate
        config.num_epochs = args.num_epochs
        config.max_steps = args.max_steps
        config.clip_eps_low = args.clip_eps
        config.clip_eps_high = args.clip_eps if args.algorithm != "dapo" else 0.28
        config.kl_weight = args.kl_weight
        config.use_lora = args.use_lora and not args.no_lora
        config.lora_r = args.lora_r
        config.use_4bit = args.use_4bit
        config.use_8bit = args.use_8bit
        config.reasoning_format = args.reasoning_format
        
        # Output –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
        if args.output_dir:
            config.output_dir = args.output_dir
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            config.output_dir = f"./output/grpo_gsm8k/{timestamp}"
    
    config.save_steps = args.save_steps
    config.log_steps = args.log_steps
    config.use_wandb = args.use_wandb
    config.wandb_project = args.wandb_project
    config.seed = args.seed
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª—å
    model_name = args.model
    if ui_config:
        model_name = ui_config.get("base_model_path") or ui_config.get("model_name", model_name)
    
    logger.info(f"–ú–æ–¥–µ–ª—å: {model_name}")
    logger.info(f"–ê–ª–≥–æ—Ä–∏—Ç–º: {config.algorithm.value}")
    logger.info(f"Output: {config.output_dir}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    dataset_file = args.dataset_file
    max_samples = args.max_samples
    dataset_language = "en"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∞–Ω–≥–ª–∏–π—Å–∫–∏–π
    
    if ui_config:
        dataset_source = ui_config.get("grpo_dataset_source", "")
        dataset_key = ui_config.get("grpo_dataset_key", "gsm8k_en")
        dataset_language = ui_config.get("grpo_dataset_language", "en")
        
        if "GSM8K" in dataset_source or dataset_key in ("gsm8k_en", "gsm8k_ru"):
            dataset_file = None  # –ò—Å–ø–æ–ª—å–∑—É–µ–º GSM8K –∏–∑ HuggingFace
            max_samples = ui_config.get("grpo_max_samples", max_samples)
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–∑—ã–∫ –ø–æ –∫–ª—é—á—É –¥–∞—Ç–∞—Å–µ—Ç–∞
            if dataset_key == "gsm8k_ru":
                dataset_language = "ru"
        else:
            dataset_file = ui_config.get("grpo_dataset_path") or ui_config.get("data_path")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª—é—á –¥–∞—Ç–∞—Å–µ—Ç–∞
    dataset_key = None
    if ui_config:
        dataset_key = ui_config.get("grpo_dataset_key")
    
    if dataset_file:
        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞: {dataset_file}")
        from .data.base import RLDataset, RLSample
        from .data.gsm8k import extract_gsm8k_final_answer
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–∞–ø–ø–∏–Ω–≥–∞ –ø–æ–ª–µ–π –∏–∑ UI –∫–æ–Ω—Ñ–∏–≥–∞
        field_mapping = {}
        prompt_template = "{{prompt}}"
        user_system_prompt = ""
        
        if ui_config:
            field_mapping = ui_config.get("grpo_field_mapping", {})
            prompt_template = ui_config.get("grpo_prompt_template", "{{prompt}}")
            user_system_prompt = ui_config.get("grpo_system_prompt", "")
        
        # –ü–æ–ª—è –¥–ª—è —á—Ç–µ–Ω–∏—è –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞
        prompt_field = field_mapping.get("prompt_field", "question")
        reference_field = field_mapping.get("reference_field", "answer")
        metadata_fields = field_mapping.get("metadata_fields", [])
        
        # Fallback –ø–æ–ª—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        prompt_fallbacks = ["question", "prompt", "input", "instruction", "problem", "query", "text"]
        reference_fallbacks = ["answer", "response", "output", "solution", "target", "completion"]
        
        logger.info(f"–ú–∞–ø–ø–∏–Ω–≥ –ø–æ–ª–µ–π: prompt={prompt_field}, reference={reference_field}")
        if prompt_template != "{{prompt}}":
            logger.info(f"–®–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞: {prompt_template[:100]}...")
        if user_system_prompt:
            logger.info(f"System prompt: {user_system_prompt[:100]}...")
        
        samples = []
        with open(dataset_file, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line:
                    data = json.loads(line)
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–æ–º–ø—Ç —Å fallback
                    raw_prompt = data.get(prompt_field)
                    if raw_prompt is None:
                        for fb in prompt_fallbacks:
                            if fb in data:
                                raw_prompt = data[fb]
                                break
                    raw_prompt = str(raw_prompt) if raw_prompt else ""
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–π –æ—Ç–≤–µ—Ç —Å fallback
                    raw_answer = data.get(reference_field)
                    if raw_answer is None:
                        for fb in reference_fallbacks:
                            if fb in data:
                                raw_answer = data[fb]
                                break
                    raw_answer = str(raw_answer) if raw_answer else ""
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç (–¥–ª—è GSM8K-—Å—Ç–∏–ª—è —Å ####)
                    ref_answer = raw_answer
                    if isinstance(raw_answer, str) and "####" in raw_answer:
                        ref_answer = extract_gsm8k_final_answer(raw_answer)
                    
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º —à–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞
                    formatted_prompt = prompt_template
                    formatted_prompt = formatted_prompt.replace("{{prompt}}", raw_prompt)
                    formatted_prompt = formatted_prompt.replace("{{reference}}", ref_answer)
                    
                    # –°–æ–±–∏—Ä–∞–µ–º metadata –∏–∑ —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –ø–æ–ª–µ–π
                    sample_metadata = {
                        "full_answer": raw_answer,
                        "raw_prompt": raw_prompt,
                    }
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –≤ metadata
                    for mf in metadata_fields:
                        if mf in data:
                            sample_metadata[mf] = data[mf]
                            # –¢–∞–∫–∂–µ –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ–º –≤ —à–∞–±–ª–æ–Ω
                            formatted_prompt = formatted_prompt.replace(f"{{{{metadata.{mf}}}}}", str(data[mf]))
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –ø–æ–ª—è –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ metadata –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –≤ reward
                    for key, value in data.items():
                        if key not in sample_metadata:
                            sample_metadata[key] = value
                        formatted_prompt = formatted_prompt.replace(f"{{{{metadata.{key}}}}}", str(value))
                    
                    samples.append(RLSample(
                        prompt=formatted_prompt,
                        reference_answer=ref_answer,
                        metadata=sample_metadata,
                    ))
        
        if max_samples:
            samples = samples[:max_samples]
        train_dataset = RLDataset(samples)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º user_system_prompt –≤ –∫–æ–Ω—Ñ–∏–≥ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ trainer
        if user_system_prompt:
            config.user_system_prompt = user_system_prompt
    else:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ HuggingFace
        dataset_names = {
            "gsm8k_en": "GSM8K (English)",
            "gsm8k_ru": "GSM8K-RU (d0rj/gsm8k-ru)",
            "math_ru": "MATH-RU (d0rj/competition_math_ru)",
            "mgsm_ru": "MGSM (juletxara/mgsm)",
        }
        ds_name = dataset_names.get(dataset_key, f"GSM8K ({dataset_language})")
        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞: {ds_name}...")
        
        train_dataset = load_gsm8k(
            split=args.split,
            max_samples=max_samples,
            reasoning_format=config.reasoning_format,
            language=dataset_language,
            dataset_key=dataset_key,
        )
    logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(train_dataset)} –ø—Ä–∏–º–µ—Ä–æ–≤")
    if len(train_dataset) <= 0:
        raise ValueError(
            "‚ùå –î–∞—Ç–∞—Å–µ—Ç –ø—É—Å—Ç–æ–π (0 –ø—Ä–∏–º–µ—Ä–æ–≤). "
            "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –≤—ã–±—Ä–∞–Ω reasoning-–¥–∞—Ç–∞—Å–µ—Ç (GSM8K/GSM8K-RU/MATH-RU), "
            "–∏ —á—Ç–æ –≤ JSONL –µ—Å—Ç—å –ø–æ–ª—è question/prompt –∏ answer/response."
        )

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ output_dir, —á—Ç–æ–±—ã UI –º–æ–≥ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ –¥–∞–Ω–Ω—ã–º
    try:
        import json as _json
        from pathlib import Path as _Path
        _cfg_path = _Path(config.output_dir) / "dataset_info.json"
        with open(_cfg_path, "w", encoding="utf-8") as f:
            _json.dump({"dataset_size": int(len(train_dataset))}, f, ensure_ascii=False, indent=2)
    except Exception:
        pass
    
    # –°–æ–∑–¥–∞—ë–º reward —Ñ—É–Ω–∫—Ü–∏—é
    if reward_rules:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –∏–∑ UI
        logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ UniversalRuleReward –∏–∑ {len(reward_rules)} –ø—Ä–∞–≤–∏–ª")
        for rule in reward_rules:
            logger.info(f"  - {rule.get('name')}: weight={rule.get('weight')}")
        reward_fn = UniversalRuleReward.from_config(reward_rules)
    else:
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è GSM8K
        logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é reward —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è GSM8K")
        reward_fn = CombinedReward([
            FormatReward(format_reward=0.2, weight=1.0),
            ReasoningQualityReward(max_reward=0.2, weight=0.5),
            GSM8KReward(correct_reward=1.0, close_reward=0.3, weight=2.0),
        ])
    
    # –°–æ–∑–¥–∞—ë–º trainer
    trainer = GRPOTrainer(
        model_name=model_name,
        config=config,
        reward_fn=reward_fn,
    )
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
    logger.info("–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")
    
    # üî• –õ–æ–≥–∏—Ä—É–µ–º system prompt —á—Ç–æ–±—ã –±—ã–ª–æ –≤–∏–¥–Ω–æ —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
    user_sys_prompt = getattr(config, 'user_system_prompt', None)
    if user_sys_prompt:
        logger.info(f"üìù System prompt (–∏–∑ UI): {user_sys_prompt[:200]}...")
    else:
        logger.info(f"üìù System prompt: (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è default –∏–∑ reasoning_format={config.reasoning_format})")
    
    trainer.train(train_dataset)
    
    logger.info("=" * 60)
    logger.info("–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    logger.info(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {config.output_dir}")
    logger.info("=" * 60)


if __name__ == "__main__":
    main()
