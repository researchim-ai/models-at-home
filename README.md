# Models at Home

**Models at Home** — инструмент для тренировки и исследования языковых моделей (LLM) в локальном окружении. Проект предоставляет графический интерфейс (Training Studio) для настройки, запуска и мониторинга процессов обучения, а также интегрированный чат для тестирования моделей.

Система построена на базе **PyTorch**, **Accelerate** и **Streamlit**, обеспечивая поддержку современных методов распределенного обучения (DDP, FSDP, DeepSpeed).

![Status](https://img.shields.io/badge/Status-Active-success) ![Python](https://img.shields.io/badge/Python-3.10%2B-blue) ![License](https://img.shields.io/badge/License-Apache_2.0-blue)

## Основные возможности

*   **Архитектура HomeLLM**:
    *   Реализация декодер-трансформера с RMSNorm, RoPE (Rotary Embeddings) и SwiGLU активацией.
    *   Поддержка Flash Attention.
    *   Weight Tying для оптимизации параметров.
    *   Полная совместимость с HuggingFace Transformers.

*   **Training Studio (GUI)**:
    *   **Визуальный конфигуратор**: Настройка гиперпараметров модели и обучения без ручного редактирования конфигурационных файлов.
    *   **Мониторинг**: Отображение графиков Loss, Learning Rate и метрик использования ресурсов (GPU/VRAM) в реальном времени.
    *   **Распределенное обучение**: Интеграция с DDP, FSDP и DeepSpeed (ZeRO-2/3) для масштабирования обучения.
    *   **Persistence**: Сохранение состояния сессии и метрик между перезагрузками интерфейса.

*   **Интегрированный Чат**:
    *   Интерфейс для инференса и тестирования обученных моделей и чекпоинтов.
    *   Настройка параметров генерации (temperature, top_p).
    *   Поддержка потоковой генерации текста.

*   **Работа с данными**:
    *   Потоковая загрузка (StreamingDataset) для работы с большими датасетами без полной загрузки в RAM.
    *   Поддержка форматов `.jsonl` и `.txt`.

## Установка

1. **Клонирование репозитория:**
   ```bash
   git clone https://github.com/yourusername/models-at-home.git
   cd models-at-home
   ```

2. **Настройка окружения:**
   ```bash
   # Создание окружения (рекомендуется)
   conda create -n homellm python=3.10
   conda activate homellm
   
   # Установка зависимостей
   pip install -r requirements.txt
   
   # Установка пакета
   pip install -e .
   ```

## Использование

### Запуск Training Studio

Для запуска графического интерфейса выполните скрипт:

```bash
./scripts/run_studio.sh
```
*Альтернативный запуск: `streamlit run homellm/app/main.py`*

Интерфейс будет доступен в браузере по адресу `http://localhost:8501`.

### Процесс работы

1.  **Конфигурация и Запуск**:
    *   Во вкладке "Запуск" выберите датасет (из директории `datasets/`).
    *   Установите параметры архитектуры модели и гиперпараметры обучения.
    *   Выберите стратегию распределенного обучения (Single GPU, DDP, DeepSpeed и др.).
    *   Запустите процесс обучения.

2.  **Мониторинг**:
    *   Во вкладке "Мониторинг" доступны графики метрик обучения и статистика использования ресурсов системы.
    *   Логи процесса (stdout/stderr) доступны для просмотра в реальном времени.

3.  **Тестирование**:
    *   Во вкладке "Чат" можно загрузить сохраненный чекпоинт или финальную модель.
    *   Доступен диалоговый интерфейс для проверки качества генерации.

## Структура проекта

*   `homellm/` — Основной пакет приложения.
    *   `models/` — Реализация модели (`HomeModel`, `HomeConfig`).
    *   `training/` — Скрипты обучения и логика работы с данными.
    *   `app/` — Код Streamlit приложения.
*   `configs/` — Конфигурационные файлы для accelerate (DeepSpeed, FSDP).
*   `datasets/` — Директория для исходных данных.
*   `out/` — Директория для сохранения артефактов обучения (чекпоинты, модели).
*   `.runs/` — Системные логи и метрики сессий.

## Распределенное обучение

Проект включает предварительно настроенные конфигурации в директории `configs/`, доступные для выбора в интерфейсе:
*   **DeepSpeed ZeRO-2**: Оптимизация памяти градиентов и оптимизатора.
*   **DeepSpeed ZeRO-3**: Полное шардирование параметров модели.
*   **ZeRO-3 Offload**: Выгрузка параметров и оптимизатора в RAM для обучения крупных моделей на GPU с ограниченной памятью.
