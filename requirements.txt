# HomeLLM - зависимости для тренировки трансформеров дома
# =========================================================
# ВАЖНО: Версии зафиксированы для совместимости pre-built wheels!
# torch 2.5.1 (PyPI, bundled CUDA 12.4) + flash-attn 2.8.3 + liger-kernel 0.6.4

# PyTorch 2.5.1 (фиксировано для flash-attn pre-built wheel)
# Устанавливается в Dockerfile из PyPI (bundled CUDA 12.4)
torch>=2.5.0,<2.6.0

# Triton (нужен для Liger Kernel, обычно идёт с torch)
triton>=2.3.0

# HuggingFace
transformers>=4.40.0
accelerate>=0.28.0
datasets>=2.19.0
safetensors>=0.4.0

# Liger Kernel 0.6.4 — оптимизированные Triton kernels для LLM
# ★ Чистый Python/Triton — ставится мгновенно!
# ★ Экономит память (не материализует logits)
# https://github.com/linkedin/Liger-Kernel
liger-kernel==0.6.4

# FlashAttention2 ставится в Dockerfile из pre-built wheel
# PEFT для LoRA/QLoRA
peft>=0.10.0
bitsandbytes>=0.43.0

# DeepSpeed (для ZeRO optimizer)
deepspeed>=0.15.0
ninja

# Rollout / inference engine (ускорение GRPO)
# vLLM даёт максимальный throughput на генерации (TP, paged-attn, batching).
# Примечание: пакет тяжёлый и зависит от CUDA; если ставите без GPU — не устанавливайте.
vllm>=0.7.3

# Утилиты
tqdm>=4.66.0
numpy>=1.24.0
pandas>=2.0.0
psutil>=5.9.0
pydantic>=2.0
pyyaml>=6.0

# Визуальное приложение (Training Studio)
streamlit>=1.32.0
plotly>=5.18.0
graphviz>=0.20.1

# Логирование и мониторинг
wandb>=0.17.0
tensorboard>=2.16.0

# RL
gymnasium[classic_control]>=0.29.0
imageio>=2.34.0
imageio-ffmpeg>=0.5.1
