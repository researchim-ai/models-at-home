# üè† Models at Home

<p align="center">
  <a href="README.md">English</a> |
  <a href="README_RU.md">–†—É—Å—Å–∫–∏–π</a>
</p>

[![License](https://img.shields.io/badge/License-Apache_2.0-green.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat&logo=docker&logoColor=white)](https://www.docker.com/)

**Models at Home** ‚Äî —ç—Ç–æ open-source —Å—Ç—É–¥–∏—è –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –∏ –¥–æ–æ–±—É—á–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) –≤ –¥–æ–º–∞—à–Ω–∏—Ö —É—Å–ª–æ–≤–∏—è—Ö. –ü—Ä–æ–µ–∫—Ç —Å–æ–∑–¥–∞–Ω, —á—Ç–æ–±—ã —Å–¥–µ–ª–∞—Ç—å —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ Deep Learning –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ.

![Screenshot](src/models-at-home.png)

## ‚ú® –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

### üéØ –†–µ–∂–∏–º—ã –æ–±—É—á–µ–Ω–∏—è
- **Pretraining** ‚Äî –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –Ω—É–ª—è –Ω–∞ —Å—ã—Ä—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- **Continual Pretraining** ‚Äî –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- **SFT (Supervised Fine-Tuning)** ‚Äî –î–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å–ª–µ–¥–æ–≤–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º –∏ –≤–µ—Å—Ç–∏ –¥–∏–∞–ª–æ–≥
- **GRPO (Group Relative Policy Optimization)** ‚Äî Reinforcement Learning –¥–ª—è –∑–∞–¥–∞—á —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è

### üñ•Ô∏è –í–∏–∑—É–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
- **GUI –≤ –±—Ä–∞—É–∑–µ—Ä–µ** ‚Äî –ù–∞—Å—Ç—Ä–æ–π–∫–∞, –∑–∞–ø—É—Å–∫ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è –±–µ–∑ –Ω–∞–ø–∏—Å–∞–Ω–∏—è –∫–æ–¥–∞
- **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏** ‚Äî –ì—Ä–∞—Ñ–∏–∫–∏ loss, learning rate, –∑–∞–≥—Ä—É–∑–∫–∏ GPU
- **–ò—Å—Ç–æ—Ä–∏—è –∑–∞–ø—É—Å–∫–æ–≤** ‚Äî –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ —Å –ª–æ–≥–∞–º–∏ –∏ —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º–∏
- **–í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è** ‚Äî –¢—É—Ç–æ—Ä–∏–∞–ª—ã –∏ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏ –ø—Ä—è–º–æ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏

### üí¨ –ß–∞—Ç –∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
- **–ß–∞—Ç —Å –º–æ–¥–µ–ª—è–º–∏** ‚Äî –¢–µ—Å—Ç–∏—Ä—É–π—Ç–µ –æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø—Ä—è–º–æ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏
- **–ü–æ–¥–¥–µ—Ä–∂–∫–∞ vLLM** ‚Äî –ë—ã—Å—Ç—Ä—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å —Å –±—ç–∫–µ–Ω–¥–æ–º vLLM
- **Chat Templates** ‚Äî –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏–∞–ª–æ–≥–æ–≤

### üì¶ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—è–º–∏
- **–ó–∞–≥—Ä—É–∑–∫–∞ —Å HuggingFace** ‚Äî –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ –æ–¥–∏–Ω –∫–ª–∏–∫ (SmolLM2, Pythia, Qwen, TinyLlama)
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–∞–∫ –±–∞–∑—É** ‚Äî –°–∫–∞—á–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è Continual Pretraining –∏–ª–∏ SFT

### üíæ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã–º–∏
- **HuggingFace Datasets** ‚Äî –°—Ç—Ä–∏–º–∏–Ω–≥ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ HuggingFace Hub
- **–§–∏–ª—å—Ç—Ä—ã –∏ –ª–∏–º–∏—Ç—ã** ‚Äî –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ —Ä–∞–∑–º–µ—Ä—É, —Ñ–∏–ª—å—Ç—Ä—ã –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —è–∑—ã–∫–∞
- **–ê–≤—Ç–æ–¥–µ—Ç–µ–∫—Ç** ‚Äî –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ (Chat/Instruct)

### ‚ö° –†–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
- **Multi-GPU** ‚Äî –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ GPU
- **FSDP** ‚Äî PyTorch Fully Sharded Data Parallel
- **DeepSpeed ZeRO** ‚Äî ZeRO-2, ZeRO-3, CPU Offload

### üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏
- –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä (Llama-style) —Å RoPE, SwiGLU, RMSNorm
- Flash Attention –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
- KV-Cache –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏

### üåê –ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
- **–ê–Ω–≥–ª–∏–π—Å–∫–∏–π** –∏ **–†—É—Å—Å–∫–∏–π** –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
- –õ–µ–≥–∫–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ —è–∑—ã–∫–∏

---

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (Docker) ‚Äî –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è

–°–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å—Ç—É–¥–∏—é, –Ω–µ –º—É—á–∞—è—Å—å —Å —É—Å—Ç–∞–Ω–æ–≤–∫–æ–π CUDA –∏ PyTorch.

### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è
- **Docker Desktop** (Windows/Mac) –∏–ª–∏ **Docker Engine** (Linux)

### –ó–∞–ø—É—Å–∫

1. **–ö–ª–æ–Ω–∏—Ä—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π:**
   ```bash
   git clone https://github.com/researchim-ai/models-at-home.git
   cd models-at-home
   ```

2. **–ó–∞–ø—É—Å—Ç–∏—Ç–µ —á–µ—Ä–µ–∑ Docker Compose:**
   ```bash
   docker-compose up --build
   ```

3. **–û—Ç–∫—Ä–æ–π—Ç–µ –≤ –±—Ä–∞—É–∑–µ—Ä–µ:**
   –ü–µ—Ä–µ–π–¥–∏—Ç–µ –ø–æ –∞–¥—Ä–µ—Å—É: [http://localhost:8501](http://localhost:8501)

–í—Å–µ –¥–∞–Ω–Ω—ã–µ (–¥–∞—Ç–∞—Å–µ—Ç—ã, –≤–µ—Å–∞ –º–æ–¥–µ–ª–µ–π, –ª–æ–≥–∏) —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ –ø–∞–ø–∫–∞—Ö `datasets/`, `out/` –∏ `.runs/` –Ω–∞ –≤–∞—à–µ–º –∫–æ–º–ø—å—é—Ç–µ—Ä–µ.

---

## üõ†Ô∏è –ó–∞–ø—É—Å–∫ –±–µ–∑ Docker (–õ–æ–∫–∞–ª—å–Ω–æ)

–ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –∑–∞–ø—É—Å–∫–∞—Ç—å –∫–æ–¥ –Ω–∞–ø—Ä—è–º—É—é –≤ —Å–≤–æ–µ–π —Å–∏—Å—Ç–µ–º–µ.

### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è
- Python 3.10+
- CUDA Toolkit 11.8+ (–¥–ª—è GPU)

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞

1. **–°–æ–∑–¥–∞–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ:**
   ```bash
   python -m venv venv
   
   # Linux/Mac
   source venv/bin/activate
   
   # Windows
   venv\Scripts\activate
   ```

2. **–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ PyTorch (—Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA):**
   –ü–æ—Å–µ—Ç–∏—Ç–µ [pytorch.org](https://pytorch.org/get-started/locally/) –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã –ø–æ–¥ –≤–∞—à—É —Å–∏—Å—Ç–µ–º—É. –ù–∞–ø—Ä–∏–º–µ—Ä:
   ```bash
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
   ```

3. **–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:**
   ```bash
   pip install -r requirements.txt
   ```

4. **–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–∞–∫–µ—Ç –≤ —Ä–µ–∂–∏–º–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏:**
   ```bash
   pip install -e .
   ```

5. **–ù–∞—Å—Ç—Ä–æ–π—Ç–µ Accelerate (–æ–¥–∏–Ω —Ä–∞–∑):**
   ```bash
   accelerate config
   ```

### –ó–∞–ø—É—Å–∫ –°—Ç—É–¥–∏–∏

–ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç:
```bash
./scripts/run_studio.sh
# –ò–ª–∏ –Ω–∞ Windows:
streamlit run homellm/app/LLM.py
```

---

## üìö –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
models-at-home/
‚îú‚îÄ‚îÄ homellm/                    # –û—Å–Ω–æ–≤–Ω–æ–π –ø–∞–∫–µ—Ç
‚îÇ   ‚îú‚îÄ‚îÄ models/                 # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–µ–π
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ home_model.py       # HomeConfig, HomeForCausalLM
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ home_model_moe.py   # Mixture of Experts –≤–∞—Ä–∏–∞–Ω—Ç
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ blueprint.py        # –í–∏–∑—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –º–æ–¥–µ–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ training/               # –°–∫—Ä–∏–ø—Ç—ã –æ–±—É—á–µ–Ω–∏—è
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pretrain.py         # –ü—Ä–µ—Ç—Ä–µ–π–Ω
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sft.py              # Supervised Fine-Tuning
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rl/                 # Reinforcement Learning (GRPO)
‚îÇ   ‚îú‚îÄ‚îÄ app/                    # Streamlit GUI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ LLM.py              # –ì–ª–∞–≤–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ docs.py             # –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ cli/                    # –ö–æ–º–∞–Ω–¥–Ω–∞—è —Å—Ç—Ä–æ–∫–∞
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chat.py             # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —á–∞—Ç
‚îÇ   ‚îî‚îÄ‚îÄ i18n/                   # –ò–Ω—Ç–µ—Ä–Ω–∞—Ü–∏–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è
‚îÇ       ‚îî‚îÄ‚îÄ locales/            # en.json, ru.json
‚îú‚îÄ‚îÄ configs/                    # –ö–æ–Ω—Ñ–∏–≥–∏ Accelerate/DeepSpeed
‚îú‚îÄ‚îÄ datasets/                   # –°–∫–∞—á–∞–Ω–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã
‚îú‚îÄ‚îÄ models/                     # –°–∫–∞—á–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
‚îî‚îÄ‚îÄ out/                        # –û–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏ —á–µ–∫–ø–æ–∏–Ω—Ç—ã
```

---

## üìä –ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è

### 1. Pretraining (–û–±—É—á–µ–Ω–∏–µ —Å –Ω—É–ª—è)

–û–±—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Å—ã—Ä—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:

1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –≤–∫–ª–∞–¥–∫—É **üíæ –î–∞–Ω–Ω—ã–µ**
2. –í—ã–±–µ—Ä–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ—Ä–ø—É—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä, FineWeb-2)
3. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ª–∏–º–∏—Ç—ã –∏ —Å–∫–∞—á–∞–π—Ç–µ
4. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –≤–∫–ª–∞–¥–∫—É **üöÄ –ó–∞–ø—É—Å–∫**
5. –í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º **Pretraining**
6. –í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–µ—Å–µ—Ç —Ä–∞–∑–º–µ—Ä–∞ –º–æ–¥–µ–ª–∏ (Tiny, Small, Base –∏ —Ç.–¥.)
7. –ù–∞–∂–º–∏—Ç–µ **‚ñ∂Ô∏è –ù–∞—á–∞—Ç—å —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É**

### 2. SFT (Supervised Fine-Tuning)

–ü—Ä–µ–≤—Ä–∞—Ç–∏—Ç–µ –ø—Ä–µ—Ç—Ä–µ–π–Ω-–º–æ–¥–µ–ª—å –≤ —á–∞—Ç-–±–æ—Ç–∞:

1. –°–∫–∞—á–∞–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, OpenOrca)
2. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ **üöÄ –ó–∞–ø—É—Å–∫** ‚Üí —Ä–µ–∂–∏–º **SFT**
3. –í—ã–±–µ—Ä–∏—Ç–µ –≤–∞—à—É –ø—Ä–µ—Ç—Ä–µ–π–Ω-–º–æ–¥–µ–ª—å –∫–∞–∫ –±–∞–∑–æ–≤—É—é
4. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ chat template –∏ –º–∞–ø–ø–∏–Ω–≥ –ø–æ–ª–µ–π
5. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ

### 3. GRPO (Reinforcement Learning)

–£–ª—É—á—à–∏—Ç–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é reward-based –æ–±—É—á–µ–Ω–∏—è:

1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ **üöÄ –ó–∞–ø—É—Å–∫** ‚Üí —Ä–µ–∂–∏–º **GRPO**
2. –í—ã–±–µ—Ä–∏—Ç–µ SFT-–º–æ–¥–µ–ª—å –∫–∞–∫ –±–∞–∑–æ–≤—É—é
3. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–∞–≥—Ä–∞–¥ (—Ñ–æ—Ä–º–∞—Ç, –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏)
4. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã rollout
5. –ó–∞–ø—É—Å—Ç–∏—Ç–µ RL-–æ–±—É—á–µ–Ω–∏–µ

### 4. –ß–∞—Ç —Å –º–æ–¥–µ–ª—å—é

–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å:

1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –≤–∫–ª–∞–¥–∫—É **üí¨ –ß–∞—Ç**
2. –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –∏–ª–∏ —á–µ–∫–ø–æ–∏–Ω—Ç
3. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
4. –ù–∞—á–Ω–∏—Ç–µ –æ–±—â–µ–Ω–∏–µ!

---

## ‚ö° –†–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ

| –†–µ–∂–∏–º | –ö–æ–Ω—Ñ–∏–≥ | –û–ø–∏—Å–∞–Ω–∏–µ | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |
|-------|--------|----------|-------------------|
| **Multi-GPU (DDP)** | `accelerate_multi_gpu.yaml` | –†–µ–ø–ª–∏–∫–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ | –ú–æ–¥–µ–ª—å –ø–æ–º–µ—â–∞–µ—Ç—Å—è –≤ 1 GPU |
| **FSDP** | `accelerate_fsdp.yaml` | PyTorch Fully Sharded | >1B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –Ω–µ—Å–∫–æ–ª—å–∫–æ GPU |
| **DeepSpeed ZeRO-2** | `accelerate_deepspeed_zero2.yaml` | –®–∞—Ä–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ | 100M-1B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ |
| **DeepSpeed ZeRO-3** | `accelerate_deepspeed_zero3.yaml` | –ü–æ–ª–Ω–æ–µ —à–∞—Ä–¥–∏—Ä–æ–≤–∞–Ω–∏–µ | >1B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ |
| **ZeRO-3 + Offload** | `accelerate_deepspeed_zero3_offload.yaml` | –®–∞—Ä–¥–∏—Ä–æ–≤–∞–Ω–∏–µ + CPU offload | –û—á–µ–Ω—å –±–æ–ª—å—à–∏–µ –º–æ–¥–µ–ª–∏ |

---

## üìà –†–∞–∑–º–µ—Ä—ã –º–æ–¥–µ–ª–µ–π

| –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è | –ü–∞—Ä–∞–º–µ—Ç—Ä—ã | VRAM (fp16) | –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è |
|--------------|-----------|-------------|--------------|
| Tiny (512-8-8) | ~25M | ~2 GB | GTX 1060+ |
| Small (768-12-12) | ~80M | ~4 GB | RTX 2060+ |
| Base (1024-16-16) | ~200M | ~8 GB | RTX 3080+ |
| Medium (1536-24-16) | ~400M | ~12 GB | RTX 3090+ |
| Large (2048-24-16) | ~700M | ~16 GB | RTX 4090+ |

---

## üîó –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å HuggingFace

–ú–æ–¥–µ–ª–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–º–µ—Å—Ç–∏–º—ã —Å —ç–∫–æ—Å–∏—Å—Ç–µ–º–æ–π HuggingFace:

```python
from homellm.models import HomeConfig, HomeForCausalLM
from transformers import AutoTokenizer

# –ó–∞–≥—Ä—É–∑–∫–∞
tokenizer = AutoTokenizer.from_pretrained("gpt2")
model = HomeForCausalLM.from_pretrained("out/home_pretrain/final_model")

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
inputs = tokenizer("–ü—Ä–∏–≤–µ—Ç", return_tensors="pt")
outputs = model.generate(**inputs, max_new_tokens=50)
print(tokenizer.decode(outputs[0]))
```

---

## ü§ù –í–∫–ª–∞–¥ –≤ –ø—Ä–æ–µ–∫—Ç

–ú—ã –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤—É–µ–º Pull Requests! –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –∏–¥–µ–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è –∏–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–µ –Ω–æ–≤—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä ‚Äî –ø–∏—à–∏—Ç–µ.

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

Apache 2.0
