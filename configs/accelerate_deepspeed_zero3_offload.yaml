# HomeLLM - DeepSpeed ZeRO Stage 3 + Full CPU Offload
# ====================================================
# Максимальная экономия VRAM: всё шардируется и offload на CPU
# Позволяет тренировать ОЧЕНЬ большие модели на 1 GPU с 8-16GB VRAM
# Медленнее чем ZeRO-2/3 без offload, но позволяет уместить больше
#
# Использование:
#   accelerate launch --config_file configs/accelerate_deepspeed_zero3_offload.yaml \
#       -m homellm.training.pretrain --data_path ...

compute_environment: LOCAL_MACHINE
distributed_type: DEEPSPEED
mixed_precision: "bf16"
num_processes: 1  # Даже на 1 GPU работает!
num_machines: 1
main_training_function: main

deepspeed_config:
  zero_optimization:
    stage: 3
    
    # Полный offload на CPU
    offload_optimizer:
      device: cpu
      pin_memory: true
      buffer_count: 4
      fast_init: false
    
    offload_param:
      device: cpu
      pin_memory: true
      buffer_count: 5
      buffer_size: 100000000
      max_in_cpu: 1000000000
    
    # Настройки stage 3
    stage3_prefetch_bucket_size: 10000000
    stage3_param_persistence_threshold: 10000
    stage3_max_live_parameters: 30000000
    stage3_max_reuse_distance: 30000000
    stage3_gather_16bit_weights_on_model_save: true
    
    # Память
    sub_group_size: 10000000
    reduce_bucket_size: 10000000
    contiguous_gradients: true
    overlap_comm: false  # Отключено для стабильности при offload
  
  gradient_clipping: 1.0
  
  bf16:
    enabled: true
  
  train_batch_size: auto
  train_micro_batch_size_per_gpu: auto
  gradient_accumulation_steps: auto

dynamo_backend: "no"
