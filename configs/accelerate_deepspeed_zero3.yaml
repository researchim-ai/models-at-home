# HomeLLM - DeepSpeed ZeRO Stage 3
# =================================
# Полное шардирование: модель + оптимизатор + градиенты
# Рекомендуется для очень больших моделей (>1B) или ограниченной VRAM
#
# Использование:
#   accelerate launch --config_file configs/accelerate_deepspeed_zero3.yaml \
#       -m homellm.training.pretrain --data_path ...

compute_environment: LOCAL_MACHINE
distributed_type: DEEPSPEED
mixed_precision: "bf16"
num_processes: 2  # Измените на количество ваших GPU
num_machines: 1
main_training_function: main

deepspeed_config:
  # ZeRO Stage 3: полное шардирование
  zero_optimization:
    stage: 3
    
    # CPU Offload для оптимизатора (экономит VRAM, но медленнее)
    offload_optimizer:
      device: cpu
      pin_memory: true
    
    # CPU Offload для параметров (максимальная экономия VRAM)
    offload_param:
      device: cpu
      pin_memory: true
    
    # Подгрузка весов
    stage3_prefetch_bucket_size: 5e7
    stage3_param_persistence_threshold: 1e5
    stage3_max_live_parameters: 1e9
    stage3_max_reuse_distance: 1e9
    
    # Сбор параметров для forward/backward
    stage3_gather_16bit_weights_on_model_save: true
    
    # Оптимизации
    sub_group_size: 1e9
    reduce_bucket_size: auto
    contiguous_gradients: true
    overlap_comm: true
  
  # Градиентный клиппинг
  gradient_clipping: 1.0
  
  # BF16
  bf16:
    enabled: true
  
  # Оптимизатор
  optimizer:
    type: AdamW
    params:
      lr: auto
      betas: [0.9, 0.95]
      eps: 1e-8
      weight_decay: auto
  
  # LR Scheduler
  scheduler:
    type: WarmupDecayLR
    params:
      warmup_min_lr: 0
      warmup_max_lr: auto
      warmup_num_steps: auto
      total_num_steps: auto

  # Размер батча
  train_batch_size: auto
  train_micro_batch_size_per_gpu: auto
  gradient_accumulation_steps: auto

  # Zero Infinity (NVMe offload) - раскомментировать если нужен offload на SSD
  # zero_infinity: true
  # aio:
  #   block_size: 1048576
  #   queue_depth: 8
  #   thread_count: 1
  #   single_submit: false
  #   overlap_events: true

dynamo_backend: "no"

